{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gzmason/Relation-Extraction-Dataset-Finetuning/blob/add_and_remove_files/notebooks/pipeline_complete.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOm1Qd9beARk"
      },
      "source": [
        "# VM Environment Setup (No Need to Run Every Time)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjICiFSxJDkZ"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "**install spacy**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tc3SzYyCEU5I",
        "outputId": "8568dadc-0044-4775-a3be-bf2373f8ed45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n",
            "Collecting pip\n",
            "  Downloading pip-22.3-py3-none-any.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 30.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (57.4.0)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-65.5.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 49.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (0.37.1)\n",
            "Installing collected packages: setuptools, pip\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 57.4.0\n",
            "    Uninstalling setuptools-57.4.0:\n",
            "      Successfully uninstalled setuptools-57.4.0\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 21.1.3\n",
            "    Uninstalling pip-21.1.3:\n",
            "      Successfully uninstalled pip-21.1.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.9.0 requires jedi>=0.10, which is not installed.\u001b[0m\n",
            "Successfully installed pip-22.3 setuptools-65.5.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pkg_resources"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (3.4.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.21.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (65.5.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.7)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.3)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.1.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.4.5)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.6.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (8.1.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.64.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.9)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (21.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.10.2)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.9.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.0.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.1)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mTraceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 183, in _run_module_as_main\n",
            "    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 142, in _get_module_details\n",
            "    return _get_module_details(pkg_main_name, error)\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 109, in _get_module_details\n",
            "    __import__(pkg_name)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/__init__.py\", line 1, in <module>\n",
            "    from typing import List, Optional\n",
            "  File \"/usr/lib/python3.7/typing.py\", line 1364, in <module>\n",
            "    class NamedTupleMeta(type):\n",
            "KeyboardInterrupt\n",
            "\n",
            "Aborted!\n"
          ]
        }
      ],
      "source": [
        "# \n",
        "!pip install -U pip setuptools wheel\n",
        "!pip install -U spacy\n",
        "!python -m spacy download en_core_web_trf\n",
        "!pip install scispacy\n",
        "!pip install \"scispacy_model/en_core_sci_scibert-0.5.1.tar.gz\"\n",
        "#!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.4.0/en_ner_bc5cdr_md-0.4.0.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yLqAo_tyDrRY",
        "outputId": "1180ca6c-ca1c-4951-f661-46f5af328d90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r⠙ Loading compatibility table...\r\u001b[2K\u001b[38;5;2m✔ Loaded compatibility table\u001b[0m\n",
            "\u001b[1m\n",
            "================= Installed pipeline packages (spaCy v3.4.2) =================\u001b[0m\n",
            "\u001b[38;5;4mℹ spaCy installation: /usr/local/lib/python3.7/dist-packages/spacy\u001b[0m\n",
            "\n",
            "NAME             SPACY            VERSION                            \n",
            "en_core_web_sm   >=3.4.0,<3.5.0   \u001b[38;5;2m3.4.1\u001b[0m   \u001b[38;5;2m✔\u001b[0m\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy validate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "piWRGqWAdNNT",
        "outputId": "b56b4092-957f-4889-a501-8372cc1eeb68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch==1.8.0\n",
            "  Downloading torch-1.8.0-cp37-cp37m-manylinux1_x86_64.whl (735.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m735.5/735.5 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0) (4.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0) (1.21.6)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.1+cu113\n",
            "    Uninstalling torch-1.12.1+cu113:\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install torch==1.8.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gmK7By5JSkl"
      },
      "source": [
        "**install OpenNRE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "U7XyQ9hiGkH4",
        "outputId": "9c844143-ddb1-45ea-e58f-4c6a73e1411e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'OpenNRE'...\n",
            "remote: Enumerating objects: 1518, done.\u001b[K\n",
            "remote: Counting objects: 100% (141/141), done.\u001b[K\n",
            "remote: Compressing objects: 100% (70/70), done.\u001b[K\n",
            "remote: Total 1518 (delta 82), reused 105 (delta 71), pack-reused 1377\u001b[K\n",
            "Receiving objects: 100% (1518/1518), 266.83 MiB | 17.04 MiB/s, done.\n",
            "Resolving deltas: 100% (903/903), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/thunlp/OpenNRE.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hmQJRCL5Iiyj",
        "outputId": "19e828d6-0a79-4fc8-a56d-0a57fae876b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/OpenNRE\n"
          ]
        }
      ],
      "source": [
        "%cd OpenNRE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6qh7Pu-0IqVp",
        "outputId": "922a5b3c-1437-49b9-9ba9-b89bb6b4c88d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch==1.6.0\n",
            "  Downloading torch-1.6.0-cp37-cp37m-manylinux1_x86_64.whl (748.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m748.8/748.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers==3.4.0\n",
            "  Downloading transformers-3.4.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytest==5.3.2\n",
            "  Downloading pytest-5.3.2-py3-none-any.whl (234 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m234.5/234.5 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn==0.22.1\n",
            "  Downloading scikit_learn-0.22.1-cp37-cp37m-manylinux1_x86_64.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy==1.4.1\n",
            "  Downloading scipy-1.4.1-cp37-cp37m-manylinux1_x86_64.whl (26.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.1/26.1 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nltk>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (3.7)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0->-r requirements.txt (line 1)) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0->-r requirements.txt (line 1)) (1.21.6)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0->-r requirements.txt (line 2)) (3.17.3)\n",
            "Collecting tokenizers==0.9.2\n",
            "  Downloading tokenizers-0.9.2-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0->-r requirements.txt (line 2)) (3.8.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0->-r requirements.txt (line 2)) (4.64.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0->-r requirements.txt (line 2)) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0->-r requirements.txt (line 2)) (2.23.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sentencepiece!=0.1.92\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0->-r requirements.txt (line 2)) (21.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from pytest==5.3.2->-r requirements.txt (line 3)) (0.2.5)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest==5.3.2->-r requirements.txt (line 3)) (1.11.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.12 in /usr/local/lib/python3.7/dist-packages (from pytest==5.3.2->-r requirements.txt (line 3)) (4.13.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest==5.3.2->-r requirements.txt (line 3)) (9.0.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest==5.3.2->-r requirements.txt (line 3)) (22.1.0)\n",
            "Collecting pluggy<1.0,>=0.12\n",
            "  Downloading pluggy-0.13.1-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.22.1->-r requirements.txt (line 4)) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk>=3.6.4->-r requirements.txt (line 6)) (7.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12->pytest==5.3.2->-r requirements.txt (line 3)) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12->pytest==5.3.2->-r requirements.txt (line 3)) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.4.0->-r requirements.txt (line 2)) (3.0.9)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->transformers==3.4.0->-r requirements.txt (line 2)) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.4.0->-r requirements.txt (line 2)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.4.0->-r requirements.txt (line 2)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.4.0->-r requirements.txt (line 2)) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.4.0->-r requirements.txt (line 2)) (1.24.3)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895241 sha256=4e64e13a917e4854b4678f92641e5907d95b49fe6825434fcb68c739a7fe9d23\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/e0/77/05245143a5b31f65af6a21f7afd3219e9fa4896f918af45677\n",
            "Successfully built sacremoses\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: tokenizers, sentencepiece, torch, scipy, sacremoses, transformers, scikit-learn, pluggy, pytest\n",
            "  Attempting uninstall: scipy\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: scipy 1.7.3\n",
            "    Uninstalling scipy-1.7.3:\n",
            "      Successfully uninstalled scipy-1.7.3\n",
            "  Attempting uninstall: scikit-learn\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "  Attempting uninstall: pluggy\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: pluggy 0.7.1\n",
            "    Uninstalling pluggy-0.7.1:\n",
            "      Successfully uninstalled pluggy-0.7.1\n",
            "  Attempting uninstall: pytest\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: pytest 3.6.4\n",
            "    Uninstalling pytest-3.6.4:\n",
            "      Successfully uninstalled pytest-3.6.4\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.5 requires scikit-learn>=1.0.0, but you have scikit-learn 0.22.1 which is incompatible.\n",
            "torchvision 0.13.1+cu113 requires torch==1.12.1, but you have torch 1.6.0 which is incompatible.\n",
            "torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.6.0 which is incompatible.\n",
            "torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.6.0 which is incompatible.\n",
            "plotnine 0.8.0 requires scipy>=1.5.0, but you have scipy 1.4.1 which is incompatible.\n",
            "jaxlib 0.3.22+cuda11.cudnn805 requires scipy>=1.5, but you have scipy 1.4.1 which is incompatible.\n",
            "jax 0.3.23 requires scipy>=1.5, but you have scipy 1.4.1 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.22.1 which is incompatible.\n",
            "fastai 2.7.9 requires torch<1.14,>=1.7, but you have torch 1.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pluggy-0.13.1 pytest-5.3.2 sacremoses-0.0.53 scikit-learn-0.22.1 scipy-1.4.1 sentencepiece-0.1.97 tokenizers-0.9.2 torch-1.6.0 transformers-3.4.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LhOL0adkIqd4",
        "outputId": "0d6a4fdc-bd33-4a50-cea3-c3cf443879d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running install\n",
            "/usr/local/lib/python3.7/dist-packages/setuptools/command/install.py:37: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
            "  setuptools.SetuptoolsDeprecationWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/setuptools/command/easy_install.py:147: EasyInstallDeprecationWarning: easy_install command is deprecated. Use build and pip and other standards-based tools.\n",
            "  EasyInstallDeprecationWarning,\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating opennre.egg-info\n",
            "writing opennre.egg-info/PKG-INFO\n",
            "writing dependency_links to opennre.egg-info/dependency_links.txt\n",
            "writing top-level names to opennre.egg-info/top_level.txt\n",
            "writing manifest file 'opennre.egg-info/SOURCES.txt'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'opennre.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/opennre\n",
            "copying opennre/pretrain.py -> build/lib/opennre\n",
            "copying opennre/__init__.py -> build/lib/opennre\n",
            "creating build/lib/opennre/tokenization\n",
            "copying opennre/tokenization/utils.py -> build/lib/opennre/tokenization\n",
            "copying opennre/tokenization/bert_tokenizer.py -> build/lib/opennre/tokenization\n",
            "copying opennre/tokenization/word_tokenizer.py -> build/lib/opennre/tokenization\n",
            "copying opennre/tokenization/word_piece_tokenizer.py -> build/lib/opennre/tokenization\n",
            "copying opennre/tokenization/__init__.py -> build/lib/opennre/tokenization\n",
            "copying opennre/tokenization/basic_tokenizer.py -> build/lib/opennre/tokenization\n",
            "creating build/lib/opennre/encoder\n",
            "copying opennre/encoder/base_encoder.py -> build/lib/opennre/encoder\n",
            "copying opennre/encoder/cnn_encoder.py -> build/lib/opennre/encoder\n",
            "copying opennre/encoder/bert_encoder.py -> build/lib/opennre/encoder\n",
            "copying opennre/encoder/pcnn_encoder.py -> build/lib/opennre/encoder\n",
            "copying opennre/encoder/__init__.py -> build/lib/opennre/encoder\n",
            "creating build/lib/opennre/model\n",
            "copying opennre/model/base_model.py -> build/lib/opennre/model\n",
            "copying opennre/model/bag_one.py -> build/lib/opennre/model\n",
            "copying opennre/model/sigmoid_nn.py -> build/lib/opennre/model\n",
            "copying opennre/model/softmax_nn.py -> build/lib/opennre/model\n",
            "copying opennre/model/bag_average.py -> build/lib/opennre/model\n",
            "copying opennre/model/bag_attention.py -> build/lib/opennre/model\n",
            "copying opennre/model/__init__.py -> build/lib/opennre/model\n",
            "creating build/lib/opennre/module\n",
            "copying opennre/module/__init__.py -> build/lib/opennre/module\n",
            "creating build/lib/opennre/framework\n",
            "copying opennre/framework/bag_re.py -> build/lib/opennre/framework\n",
            "copying opennre/framework/multi_label_sentence_re.py -> build/lib/opennre/framework\n",
            "copying opennre/framework/utils.py -> build/lib/opennre/framework\n",
            "copying opennre/framework/data_loader.py -> build/lib/opennre/framework\n",
            "copying opennre/framework/sentence_re.py -> build/lib/opennre/framework\n",
            "copying opennre/framework/__init__.py -> build/lib/opennre/framework\n",
            "creating build/lib/opennre/module/nn\n",
            "copying opennre/module/nn/cnn.py -> build/lib/opennre/module/nn\n",
            "copying opennre/module/nn/rnn.py -> build/lib/opennre/module/nn\n",
            "copying opennre/module/nn/lstm.py -> build/lib/opennre/module/nn\n",
            "copying opennre/module/nn/__init__.py -> build/lib/opennre/module/nn\n",
            "creating build/lib/opennre/module/pool\n",
            "copying opennre/module/pool/max_pool.py -> build/lib/opennre/module/pool\n",
            "copying opennre/module/pool/avg_pool.py -> build/lib/opennre/module/pool\n",
            "copying opennre/module/pool/__init__.py -> build/lib/opennre/module/pool\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/opennre\n",
            "creating build/bdist.linux-x86_64/egg/opennre/tokenization\n",
            "copying build/lib/opennre/tokenization/utils.py -> build/bdist.linux-x86_64/egg/opennre/tokenization\n",
            "copying build/lib/opennre/tokenization/bert_tokenizer.py -> build/bdist.linux-x86_64/egg/opennre/tokenization\n",
            "copying build/lib/opennre/tokenization/word_tokenizer.py -> build/bdist.linux-x86_64/egg/opennre/tokenization\n",
            "copying build/lib/opennre/tokenization/word_piece_tokenizer.py -> build/bdist.linux-x86_64/egg/opennre/tokenization\n",
            "copying build/lib/opennre/tokenization/__init__.py -> build/bdist.linux-x86_64/egg/opennre/tokenization\n",
            "copying build/lib/opennre/tokenization/basic_tokenizer.py -> build/bdist.linux-x86_64/egg/opennre/tokenization\n",
            "creating build/bdist.linux-x86_64/egg/opennre/encoder\n",
            "copying build/lib/opennre/encoder/base_encoder.py -> build/bdist.linux-x86_64/egg/opennre/encoder\n",
            "copying build/lib/opennre/encoder/cnn_encoder.py -> build/bdist.linux-x86_64/egg/opennre/encoder\n",
            "copying build/lib/opennre/encoder/bert_encoder.py -> build/bdist.linux-x86_64/egg/opennre/encoder\n",
            "copying build/lib/opennre/encoder/pcnn_encoder.py -> build/bdist.linux-x86_64/egg/opennre/encoder\n",
            "copying build/lib/opennre/encoder/__init__.py -> build/bdist.linux-x86_64/egg/opennre/encoder\n",
            "creating build/bdist.linux-x86_64/egg/opennre/model\n",
            "copying build/lib/opennre/model/base_model.py -> build/bdist.linux-x86_64/egg/opennre/model\n",
            "copying build/lib/opennre/model/bag_one.py -> build/bdist.linux-x86_64/egg/opennre/model\n",
            "copying build/lib/opennre/model/sigmoid_nn.py -> build/bdist.linux-x86_64/egg/opennre/model\n",
            "copying build/lib/opennre/model/softmax_nn.py -> build/bdist.linux-x86_64/egg/opennre/model\n",
            "copying build/lib/opennre/model/bag_average.py -> build/bdist.linux-x86_64/egg/opennre/model\n",
            "copying build/lib/opennre/model/bag_attention.py -> build/bdist.linux-x86_64/egg/opennre/model\n",
            "copying build/lib/opennre/model/__init__.py -> build/bdist.linux-x86_64/egg/opennre/model\n",
            "creating build/bdist.linux-x86_64/egg/opennre/module\n",
            "creating build/bdist.linux-x86_64/egg/opennre/module/nn\n",
            "copying build/lib/opennre/module/nn/cnn.py -> build/bdist.linux-x86_64/egg/opennre/module/nn\n",
            "copying build/lib/opennre/module/nn/rnn.py -> build/bdist.linux-x86_64/egg/opennre/module/nn\n",
            "copying build/lib/opennre/module/nn/lstm.py -> build/bdist.linux-x86_64/egg/opennre/module/nn\n",
            "copying build/lib/opennre/module/nn/__init__.py -> build/bdist.linux-x86_64/egg/opennre/module/nn\n",
            "creating build/bdist.linux-x86_64/egg/opennre/module/pool\n",
            "copying build/lib/opennre/module/pool/max_pool.py -> build/bdist.linux-x86_64/egg/opennre/module/pool\n",
            "copying build/lib/opennre/module/pool/avg_pool.py -> build/bdist.linux-x86_64/egg/opennre/module/pool\n",
            "copying build/lib/opennre/module/pool/__init__.py -> build/bdist.linux-x86_64/egg/opennre/module/pool\n",
            "copying build/lib/opennre/module/__init__.py -> build/bdist.linux-x86_64/egg/opennre/module\n",
            "copying build/lib/opennre/pretrain.py -> build/bdist.linux-x86_64/egg/opennre\n",
            "creating build/bdist.linux-x86_64/egg/opennre/framework\n",
            "copying build/lib/opennre/framework/bag_re.py -> build/bdist.linux-x86_64/egg/opennre/framework\n",
            "copying build/lib/opennre/framework/multi_label_sentence_re.py -> build/bdist.linux-x86_64/egg/opennre/framework\n",
            "copying build/lib/opennre/framework/utils.py -> build/bdist.linux-x86_64/egg/opennre/framework\n",
            "copying build/lib/opennre/framework/data_loader.py -> build/bdist.linux-x86_64/egg/opennre/framework\n",
            "copying build/lib/opennre/framework/sentence_re.py -> build/bdist.linux-x86_64/egg/opennre/framework\n",
            "copying build/lib/opennre/framework/__init__.py -> build/bdist.linux-x86_64/egg/opennre/framework\n",
            "copying build/lib/opennre/__init__.py -> build/bdist.linux-x86_64/egg/opennre\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/tokenization/utils.py to utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/tokenization/bert_tokenizer.py to bert_tokenizer.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/tokenization/word_tokenizer.py to word_tokenizer.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/tokenization/word_piece_tokenizer.py to word_piece_tokenizer.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/tokenization/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/tokenization/basic_tokenizer.py to basic_tokenizer.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/encoder/base_encoder.py to base_encoder.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/encoder/cnn_encoder.py to cnn_encoder.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/encoder/bert_encoder.py to bert_encoder.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/encoder/pcnn_encoder.py to pcnn_encoder.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/encoder/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/model/base_model.py to base_model.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/model/bag_one.py to bag_one.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/model/sigmoid_nn.py to sigmoid_nn.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/model/softmax_nn.py to softmax_nn.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/model/bag_average.py to bag_average.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/model/bag_attention.py to bag_attention.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/model/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/module/nn/cnn.py to cnn.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/module/nn/rnn.py to rnn.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/module/nn/lstm.py to lstm.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/module/nn/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/module/pool/max_pool.py to max_pool.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/module/pool/avg_pool.py to avg_pool.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/module/pool/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/module/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/pretrain.py to pretrain.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/framework/bag_re.py to bag_re.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/framework/multi_label_sentence_re.py to multi_label_sentence_re.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/framework/utils.py to utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/framework/data_loader.py to data_loader.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/framework/sentence_re.py to sentence_re.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/framework/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/__init__.py to __init__.cpython-37.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying opennre.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying opennre.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying opennre.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying opennre.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "creating dist\n",
            "creating 'dist/opennre-0.1-py3.7.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing opennre-0.1-py3.7.egg\n",
            "Copying opennre-0.1-py3.7.egg to /usr/lib/python3.7/site-packages\n",
            "Adding opennre 0.1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/lib/python3.7/site-packages/opennre-0.1-py3.7.egg\n",
            "Processing dependencies for opennre==0.1\n",
            "Finished processing dependencies for opennre==0.1\n"
          ]
        }
      ],
      "source": [
        "!python setup.py install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UkGhT655dktZ",
        "outputId": "b9376ed8-9365-4bee-8701-ff45acc0ec8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd ../"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSZesWH5ewNy"
      },
      "source": [
        "**install sentencepiece for transformers dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qLepxKvKfCZ-",
        "outputId": "da6fcf17-15e7-4739-c5d2-1c6d6c6dd1ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers==4.11.0\n",
            "  Downloading transformers-4.11.0-py3-none-any.whl (2.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.11.0) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.11.0) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.11.0) (2022.6.2)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.11.0) (0.0.53)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.11.0) (4.64.1)\n",
            "Collecting huggingface-hub>=0.0.17\n",
            "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.5/163.5 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.11.0) (3.8.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.11.0) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.11.0) (2.23.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.11.0) (4.13.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.17->transformers==4.11.0) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.11.0) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.11.0) (3.9.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.11.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.11.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.11.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.11.0) (2022.9.24)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.11.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.11.0) (1.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.11.0) (1.15.0)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: tokenizers 0.9.2\n",
            "    Uninstalling tokenizers-0.9.2:\n",
            "      Successfully uninstalled tokenizers-0.9.2\n",
            "  Attempting uninstall: transformers\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: transformers 3.4.0\n",
            "    Uninstalling transformers-3.4.0:\n",
            "      Successfully uninstalled transformers-3.4.0\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mSuccessfully installed huggingface-hub-0.10.1 tokenizers-0.10.3 transformers-4.11.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.97)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install transformers==4.11.0 # last version 4.1.0\n",
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_pMYlv6cadb"
      },
      "source": [
        "**install pubmed-parser**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "E6-Fg3CHNy-4",
        "outputId": "3d85e3bd-3e80-4645-b01a-401c4284209c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pubmed-parser\n",
            "  Downloading pubmed_parser-0.3.1.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from pubmed-parser) (4.9.1)\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.6-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.9/235.9 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pubmed-parser) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pubmed-parser) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pubmed-parser) (1.21.6)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from pubmed-parser) (5.3.2)\n",
            "Collecting pytest-cov\n",
            "  Downloading pytest_cov-4.0.0-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: importlib-metadata>=0.12 in /usr/local/lib/python3.7/dist-packages (from pytest->pubmed-parser) (4.13.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from pytest->pubmed-parser) (0.2.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytest->pubmed-parser) (21.3)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->pubmed-parser) (9.0.0)\n",
            "Requirement already satisfied: pluggy<1.0,>=0.12 in /usr/local/lib/python3.7/dist-packages (from pytest->pubmed-parser) (0.13.1)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->pubmed-parser) (1.11.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->pubmed-parser) (22.1.0)\n",
            "Collecting coverage[toml]>=5.2.1\n",
            "  Downloading coverage-6.5.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (210 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.1/210.1 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pubmed-parser) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pubmed-parser) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pubmed-parser) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pubmed-parser) (2022.9.24)\n",
            "Requirement already satisfied: tomli in /usr/local/lib/python3.7/dist-packages (from coverage[toml]>=5.2.1->pytest-cov->pubmed-parser) (2.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12->pytest->pubmed-parser) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12->pytest->pubmed-parser) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->pytest->pubmed-parser) (3.0.9)\n",
            "Building wheels for collected packages: pubmed-parser\n",
            "  Building wheel for pubmed-parser (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pubmed-parser: filename=pubmed_parser-0.3.1-py3-none-any.whl size=18494 sha256=bfb96d1a77b0c6dfedbe82e55fc24e0f54535dd789a0f430b86b46aee9bcdc82\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/72/13/2312faacbfdcc3d444af56ac496dd4994015df101606059eeb\n",
            "Successfully built pubmed-parser\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: unidecode, coverage, pytest-cov, pubmed-parser\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mSuccessfully installed coverage-6.5.0 pubmed-parser-0.3.1 pytest-cov-4.0.0 unidecode-1.3.6\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install pubmed-parser"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDrUSe47yXeH"
      },
      "source": [
        "**install gensim**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKZAT_TAyW4v"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTGeW6FHQkyd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCfQEdKbd4Ze"
      },
      "source": [
        "# Main Scripts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTEhxFbrMJ0c"
      },
      "source": [
        "**Connect to MongoDB and Load PubMed Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6rUtQypYMIPv"
      },
      "outputs": [],
      "source": [
        "import pymongo\n",
        "with open('/content/connection_mongodb.txt') as f:\n",
        "  mongodb_link = f.readline()\n",
        "\n",
        "client = pymongo.MongoClient(mongodb_link)\n",
        "# Database Name\n",
        "db = client['pubmed']\n",
        "# Collection Name\n",
        "col = db['abstracts']\n",
        "\n",
        "abstracts = col.find({},{'_id':0, 'text':1})\n",
        "abstracts = [a['text'] for a in abstracts]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ee4dtfu1TD_w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27d75314-cc36-4a16-f3da-588d71356be3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Severe COVID-19 is associated with venous thromboembolic events and and immuno-thrombotic phenomena, responsible for pulmonary vascular damage. This review summarizes the current knowledge on thrombotic risk in COVID-19 inpatients, the potential predictive factors (including D-dimer) and the randomized trials studying the effect of intermediate or therapeutic-dose anticoagulation on the clinical and thrombotic prognosis. Despite the initial hope, therapeutic anticoagulation does not improve the clinical prognosis in critically ill inpatients, and standard prophylactic anticoagulation is therefore recommended. In non-critical inpatients, the use of therapeutic anticoagulation may help reduce the risk of severe clinical deterioration, but its risk-benefit will be clarified in ongoing studies and meta-analyzes.\n"
          ]
        }
      ],
      "source": [
        "print(abstracts[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhLSadL0Mo2C"
      },
      "source": [
        "**Use NER to extract entities**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JeGZVhuvExKK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acf61a10-e361-4fa8-9e74-29da25b29352"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "import spacy\n",
        "%cd /content\n",
        "with open(\"/content/simple_dict.txt\",\"rb\") as file:\n",
        "  simple_dict = pickle.load(file)\n",
        "#nlp = spacy.load(\"en_core_sci_scibert\")\n",
        "nlp = spacy.load(\"en_core_sci_lg\")\n",
        "\n",
        "import inflect\n",
        "inflect_converter = inflect.engine()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0VkWb4iurW6"
      },
      "outputs": [],
      "source": [
        "def entity_extraction(text_input):\n",
        "  doc = nlp(text_input)\n",
        "  ignore_list = []\n",
        "  text_entity_list = []\n",
        "  for sentence in doc.sents:\n",
        "    sentence_entity_list = []\n",
        "    entity_start = -1\n",
        "    entity_end = -1\n",
        "    and_keyword_connecting = False\n",
        "    prev_adp = False\n",
        "    parenthesis_count = 0\n",
        "\n",
        "    for token in sentence:\n",
        "      if (token.ent_type != 0 and token.tag_ == 'JJ'):\n",
        "        if entity_start == -1: # Entering a new entity\n",
        "          entity_start = token.idx\n",
        "      elif (token.ent_type != 0 and token.pos_ == 'NOUN'):\n",
        "        if entity_start == -1: # Entering a new entity\n",
        "          entity_start = token.idx\n",
        "        entity_end = token.idx + len(token) # Possible to end an entity here\n",
        "      elif token.ent_type != 0 and not prev_adp:\n",
        "        entity_start = -1\n",
        "        entity_end = -1\n",
        "        prev_adp = False\n",
        "      elif (token.text == \"of\"): #ignore the previous entity\n",
        "        entity_start = -1\n",
        "        entity_end = -1\n",
        "      elif (token.pos_ == 'ADP'): #only take entities after proposition\n",
        "        prev_adp = True\n",
        "      elif (token.text == \"and\" and entity_end == -1): #if not yet reaches the end of an entity\n",
        "        continue\n",
        "      else: \n",
        "        #checks if an entity has been formed\n",
        "        if (entity_start != -1 and entity_end != -1):\n",
        "          if and_keyword_connecting and sentence_entity_list and (entity_end - sentence_entity_list[-1]['end'] <= 30): \n",
        "            #if close enough with previous entity and connected by \"AND\"\n",
        "            sentence_entity_list[-1]['end'] = entity_end\n",
        "          else: \n",
        "            #if is an independent entity and not inside a parenthesis\n",
        "            if parenthesis_count == 0:\n",
        "              sentence_entity_list.append({\"start\": entity_start, \"end\": entity_end, \"label\": \"Entity\"})\n",
        "            else:\n",
        "              ignore_list.append(doc.text[entity_start:entity_end])\n",
        "          and_keyword_connecting = False\n",
        "\n",
        "        elif token.pos_ == \"NOUN\" and and_keyword_connecting:\n",
        "          #if is a noun (but not recognized as an entity) and should be connected by AND keyword\n",
        "          if sentence_entity_list and (token.idx + len(token) - sentence_entity_list[-1]['end'] <= 30):\n",
        "            sentence_entity_list[-1]['end'] = token.idx + len(token)\n",
        "          and_keyword_connecting = False\n",
        "        \n",
        "        if token.text == 'and':\n",
        "          and_keyword_connecting = True\n",
        "\n",
        "        entity_start = -1\n",
        "        entity_end = -1\n",
        "\n",
        "      # If we enter a parenthesis, all independent entities inside it should not be considered\n",
        "      if (token.text == \"(\"):\n",
        "        parenthesis_count = parenthesis_count + 1\n",
        "      elif (token.text == \")\"):\n",
        "        parenthesis_count = parenthesis_count - 1\n",
        "\n",
        "    for ent in sentence_entity_list:\n",
        "      start_index = ent['start']\n",
        "      end_index = ent['end']\n",
        "      entity_text = doc.text[start_index:end_index]\n",
        "      lower_text = entity_text.lower()\n",
        "\n",
        "\n",
        "      #Only consider it to be an entity if it is not a simple word and has not occured within a parethesis\n",
        "      should_add = True\n",
        "      if lower_text in simple_dict or inflect_converter.singular_noun(lower_text) in simple_dict :\n",
        "        should_add = False\n",
        "\n",
        "      for ignore_word in ignore_list:\n",
        "        if ignore_word in entity_text:\n",
        "          should_add = False\n",
        "\n",
        "      if should_add:\n",
        "        text_entity_list.append(ent)\n",
        "\n",
        "  ex = {\n",
        "      \"text\": doc.text,\n",
        "      \"ents\": text_entity_list,\n",
        "      \"title\": None\n",
        "  }\n",
        "\n",
        "  #spacy.displacy.render(ex , style='ent', manual=True, jupyter=True)\n",
        "\n",
        "  return ex"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXCQCltfqLQU"
      },
      "source": [
        "**Use OpenNRE to check if there is relationship between two entities**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6m_iqxUqMUc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "589870e8-506e-40c5-e139-9c0c1f1fd6b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/OpenNRE\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd OpenNRE\n",
        "import opennre\n",
        "model = opennre.get_model('wiki80_cnn_softmax')\n",
        "%cd ../"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LCSpBpYu6O5"
      },
      "outputs": [],
      "source": [
        "# Only Input Current Sentecne to OpenNRE\n",
        "# Output Format: [{'sentence':'...', 'first_entity':'...', 'second_entity':'...'}, ...]\n",
        "import json\n",
        "def get_entity_pairs(ex):\n",
        "  doc = nlp(ex['text'])\n",
        "  period_idx_list = []\n",
        "  # find the indices of the periods\n",
        "  for token in doc:\n",
        "    if token.text == \".\":\n",
        "      period_idx_list.append(token.idx)\n",
        "\n",
        "  original_text = ex['text']\n",
        "  entities = ex['ents']\n",
        "  entity_pairs_with_confidence = []\n",
        "  curr_sentence_entity_pairs = []\n",
        "\n",
        "  for entity_index in range(0, len(entities) - 1):\n",
        "    # Go over every ADJACENT entity pairs\n",
        "    first_entity = entities[entity_index]\n",
        "    second_entity = entities[entity_index + 1]\n",
        "    if first_entity['start'] == second_entity['start']:\n",
        "      continue \n",
        "\n",
        "    period_in_between = 0\n",
        "    for p in period_idx_list:\n",
        "      if first_entity['start'] < p < second_entity['start']:\n",
        "        period_in_between += 1\n",
        "\n",
        "    # Only consider entity pairs within the SAME sentence\n",
        "    # If we reach a different sentence, compare all entity pairs in the previous sentence and get the most confident pair\n",
        "    if period_in_between > 0:\n",
        "      if len(curr_sentence_entity_pairs) > 0:\n",
        "        curr_sentence_entity_pairs.sort(key = lambda x: x[3], reverse=True) # Sort by confidence level\n",
        "        entity_pairs_with_confidence.append(curr_sentence_entity_pairs[0]) # Only the most confident pair will remain\n",
        "        curr_sentence_entity_pairs = []\n",
        "      continue\n",
        "\n",
        "\n",
        "    # Find Previous Period and Next Period and use them to cut out sentence containing the two entities\n",
        "    previous_period_order = 0 # Among all those periods, which one is right before the first entity\n",
        "    while previous_period_order < len(period_idx_list) and period_idx_list[previous_period_order] < first_entity['start']:\n",
        "      previous_period_order = previous_period_order + 1\n",
        "    previous_period_order = previous_period_order - 1\n",
        "\n",
        "    next_period_order = 0 # Among all those periods, which one is right after the second entity\n",
        "    while next_period_order < len(period_idx_list) and period_idx_list[next_period_order] < second_entity['end']:\n",
        "      next_period_order = next_period_order + 1\n",
        "\n",
        "    previous_period_pos = period_idx_list[previous_period_order]\n",
        "    if previous_period_order == -1:\n",
        "      previous_period_pos = -1\n",
        "    \n",
        "    if next_period_order == len(period_idx_list):\n",
        "      next_period_pos = len(original_text) - 1\n",
        "    else:\n",
        "      next_period_pos = period_idx_list[next_period_order]\n",
        "\n",
        "    relevant_sentence = original_text[previous_period_pos + 1 : next_period_pos + 1]\n",
        "    if relevant_sentence[0] == ' ':\n",
        "      relevant_sentence = relevant_sentence[1:]\n",
        "    # The indexes of the two entities in the cut out sentence\n",
        "    first_entity_text = original_text[first_entity['start']:first_entity['end']]\n",
        "    first_entity_start = relevant_sentence.index(first_entity_text)\n",
        "    first_entity_end = first_entity_start + (first_entity['end'] - first_entity['start'])\n",
        "\n",
        "    second_entity_text = original_text[second_entity['start']:second_entity['end']]\n",
        "    second_entity_start = relevant_sentence.index(second_entity_text)\n",
        "    second_entity_end = second_entity_start + (second_entity['end'] - second_entity['start'])\n",
        "\n",
        "    # inferred relation format: ('father', 0.7654321)\n",
        "    inferred_relation = model.infer({'text': relevant_sentence, \n",
        "                      'h': {'pos': (first_entity_start, first_entity_end)}, \n",
        "                      't': {'pos': (second_entity_start, second_entity_end)}})\n",
        "    \n",
        "    confidence_level = inferred_relation[1]\n",
        "\n",
        "    relevant_text_between = relevant_sentence[first_entity_end:second_entity_start]\n",
        "\n",
        "    curr_sentence_entity_pairs.append((  relevant_sentence,relevant_text_between,\n",
        "                        relevant_sentence[first_entity_start:first_entity_end],\n",
        "                        relevant_sentence[second_entity_start:second_entity_end],\n",
        "                        confidence_level))\n",
        "\n",
        "  if len(curr_sentence_entity_pairs) > 0:\n",
        "    curr_sentence_entity_pairs.sort(key = lambda x: x[4], reverse=True) # Sort by confidence level\n",
        "    entity_pairs_with_confidence.append(curr_sentence_entity_pairs[0]) # Only the most confident pair will remain\n",
        "    curr_sentence_entity_pairs = []\n",
        "\n",
        "  entity_pairs = []\n",
        "  for entity_pair in entity_pairs_with_confidence:\n",
        "    entity_pairs.append({'sentence': entity_pair[0], 'text_between': entity_pair[1], 'first_entity': entity_pair[2], 'second_entity': entity_pair[3]})\n",
        "\n",
        "  #entity_pairs = json.dumps(entity_pairs)\n",
        "  return entity_pairs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,1000):\n",
        "  abstract = abstracts[i]\n",
        "  if 'Here, we summarise the origins and types of 375' in abstract:\n",
        "    print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEj_zgxWB49d",
        "outputId": "9fef730f-3c0c-472d-c114-e7580dd6a343"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "317\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_text.find(\"bring\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxsuoacFYLiz",
        "outputId": "ac0912b1-6581-40bf-da72-0e578162e6d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "137"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = 'The principle of treatment for advanced stage CRC is a multidisciplinary and comprehensive treatment based on chemotherapy, which always bring significant toxic side effects.'\n",
        "ex = entity_extraction(input_text)\n",
        "\n",
        "colors = {'Entity1': \"#85C1E9\", 'Entity2': \"#85C1E9\", \"Relation\": \"#ff6961\"}\n",
        "options = {'colors':colors}\n",
        "\n",
        "ex['ents'] = [{'start': 110, 'end': 122, 'label': 'Entity1'}, {'start': 143, 'end': 173, 'label': 'Entity2'}, {'start': 137, 'end': 142, 'label': 'Relation'}]\n",
        "print(ex['ents'])\n",
        "spacy.displacy.render(ex , style='ent', manual=True, jupyter=True, options = options)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "id": "SDuKooRPVrXl",
        "outputId": "75ff069a-c98d-43dc-ccba-88e574b906ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'start': 110, 'end': 122, 'label': 'Entity1'}, {'start': 143, 'end': 173, 'label': 'Entity2'}, {'start': 137, 'end': 142, 'label': 'Relation'}]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">The principle of treatment for advanced stage CRC is a multidisciplinary and comprehensive treatment based on \n",
              "<mark class=\"entity\" style=\"background: #85C1E9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    chemotherapy\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Entity1</span>\n",
              "</mark>\n",
              ", which always \n",
              "<mark class=\"entity\" style=\"background: #ff6961; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    bring\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Relation</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #85C1E9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    significant toxic side effects\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Entity2</span>\n",
              "</mark>\n",
              ".</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#get entity pairs from abstracts\n",
        "input_text = abstracts[317]\n",
        "ex = entity_extraction(input_text)\n",
        "entity_pairs = get_entity_pairs(ex)\n",
        "entity_pairs "
      ],
      "metadata": {
        "id": "SBU-xdjrEDla",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 809
        },
        "outputId": "3e21c9eb-452b-4d12-9e78-845ee2707970"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Covering\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Entity</span>\n",
              "</mark>\n",
              ": September 1972 to December 2020Explorations of \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    complex symbioses\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Entity</span>\n",
              "</mark>\n",
              " have often elucidated a plethora of previously undescribed \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    chemical compounds\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Entity</span>\n",
              "</mark>\n",
              " that may serve \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    ecological functions in signalling\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Entity</span>\n",
              "</mark>\n",
              ", communication or \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    defence\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Entity</span>\n",
              "</mark>\n",
              ". A case in point is the subfamily of \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    termites\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Entity</span>\n",
              "</mark>\n",
              " that cultivate a \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    fungus\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Entity</span>\n",
              "</mark>\n",
              " as their primary \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    food source\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Entity</span>\n",
              "</mark>\n",
              " and maintain \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    complex bacterial communities\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Entity</span>\n",
              "</mark>\n",
              ", from which a series of \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    novel compound discoveries\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Entity</span>\n",
              "</mark>\n",
              " have been made. Here, we summarise the \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    origins and types\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Entity</span>\n",
              "</mark>\n",
              " of 375 compounds that have been discovered from the \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    symbiosis\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Entity</span>\n",
              "</mark>\n",
              " over the past four decades and discuss the \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    potential for synergistic actions between compounds\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Entity</span>\n",
              "</mark>\n",
              " within the \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    complex chemical mixtures\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Entity</span>\n",
              "</mark>\n",
              " in which they exist. We go on to highlight how vastly underexplored the diversity and geographic distribution of the \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    symbiosis\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Entity</span>\n",
              "</mark>\n",
              " is, which leaves ample potential for natural product discovery of compounds of both ecological and medical importance.</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'first_entity': 'chemical compounds',\n",
              "  'second_entity': 'ecological functions in signalling',\n",
              "  'sentence': 'Covering: September 1972 to December 2020Explorations of complex symbioses have often elucidated a plethora of previously undescribed chemical compounds that may serve ecological functions in signalling, communication or defence.',\n",
              "  'text_between': ' that may serve '},\n",
              " {'first_entity': 'complex bacterial communities',\n",
              "  'second_entity': 'novel compound discoveries',\n",
              "  'sentence': 'A case in point is the subfamily of termites that cultivate a fungus as their primary food source and maintain complex bacterial communities, from which a series of novel compound discoveries have been made.',\n",
              "  'text_between': ', from which a series of '},\n",
              " {'first_entity': 'origins and types',\n",
              "  'second_entity': 'symbiosis',\n",
              "  'sentence': 'Here, we summarise the origins and types of 375 compounds that have been discovered from the symbiosis over the past four decades and discuss the potential for synergistic actions between compounds within the complex chemical mixtures in which they exist.',\n",
              "  'text_between': ' of 375 compounds that have been discovered from the '}]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Perform* entity extraction and entity pairs for first 1000 docs:"
      ],
      "metadata": {
        "id": "X0uAi-tQnSFf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "entities_all_docs = []\n",
        "for i in range(len(abstracts[:1000])):\n",
        "  input_text = abstracts[i]\n",
        "  ex = entity_extraction(input_text)\n",
        "  entity_pairs = get_entity_pairs(ex)\n",
        "  entities_all_docs.append(entity_pairs)"
      ],
      "metadata": {
        "id": "M9X4IQCnnh8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "with open('/content/entities_1000_docs.json', 'w') as f:\n",
        "    json.dump(entities_all_docs, f)"
      ],
      "metadata": {
        "id": "9BdPzcDapPra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "entities_all_docs = []\n",
        "for i in range(len(abstracts[:10000])):\n",
        "  input_text = abstracts[i]\n",
        "  ex = entity_extraction(input_text)\n",
        "  entity_pairs = get_entity_pairs(ex)\n",
        "  entities_all_docs.append(entity_pairs)"
      ],
      "metadata": {
        "id": "ff5TxOpsLS7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "with open('/content/entities_10000_docs.json', 'w') as f:\n",
        "    json.dump(entities_all_docs, f)"
      ],
      "metadata": {
        "id": "C6E0E_xWLUHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moGXBmfhVWuG"
      },
      "source": [
        "**auto-summarization transformers**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103,
          "referenced_widgets": [
            "46f8c38bf4be44fb96a72b5e3d343a34",
            "d1672e3c4d9f48f1af411aabb33228df",
            "8782b8f894444c9aaa095f865f306ba2",
            "d2f02a1ab9904c379741a4878dfc538d",
            "392539877f58454985e093b71c44809a",
            "750a172e34a34850ad655cdc9ba3e53a",
            "86789169614248eeab098764b774780b",
            "a43f7a9a3d814e54912c78a4ee786a51",
            "0f3633cf17e244cf9c17e18f074ffd85",
            "2f5552fea4da4d858d1fba2c8a01ab81",
            "6caf30d1f43345ac8601fc3ad5cf668f"
          ]
        },
        "id": "4jZz-YxLQc-B",
        "outputId": "d59b2431-13d0-4df2-b282-07e807839c70"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/configuration_utils.py:337: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
            "  \"Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 \"\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "46f8c38bf4be44fb96a72b5e3d343a34",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/2.75G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "\n",
        "# Download configuration from huggingface.co (user-uploaded) and cached, use cache_dir to change cache dir\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"sysresearch101/t5-large-finetuned-xsum-cnn\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"sysresearch101/t5-large-finetuned-xsum-cnn\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XVmLLAT4VDIb"
      },
      "outputs": [],
      "source": [
        "# abstract[10][0]\n",
        "ARTICLE_TO_SUMMARIZE = '''Extracellular matrixes (ECMs), such as the cell walls and biofilms, \n",
        "are important for supporting cell integrity and function and regulating intercellular communication.'''\n",
        "ARTICLE_TO_SUMMARIZE_MASKED = '''[MASK], such as the [MASK], \n",
        "are important for supporting [MASK] and regulating [MASK].'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LERP3joEYIe1"
      },
      "source": [
        "problem:\n",
        "1. 1 to many relationship. i.e. ECMs support cell integrity and function; ECMs regulate intercellular communication. How to identify this and use ECMs twice\n",
        "2. maskand decode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqE1GijKQuSa",
        "outputId": "2ce4f70a-e351-4db0-a96a-0d2daed83be4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[MASK] is a group of people who work together to promote and protect the rights of children.\n"
          ]
        }
      ],
      "source": [
        "input_ids = tokenizer.encode(ARTICLE_TO_SUMMARIZE_MASKED, return_tensors='pt')\n",
        "summary_ids = model.generate(input_ids,\n",
        "            min_length=20,\n",
        "            max_length=80,\n",
        "            num_beams=10,\n",
        "            repetition_penalty=2.5,\n",
        "            length_penalty=1.0,\n",
        "            early_stopping=True,\n",
        "            no_repeat_ngram_size=2,\n",
        "            use_cache=True,\n",
        "            do_sample = True,\n",
        "            temperature = 0.8,\n",
        "            top_k = 50,\n",
        "            top_p = 0.95)\n",
        "\n",
        "summary_text = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "print(summary_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2qOunFgSY3fJ"
      },
      "outputs": [],
      "source": [
        "after_ner = '''A are important for supporting B'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTz-up68ZDyj",
        "outputId": "45a1c7c5-8b2a-4ce5-9fe9-54af3b592dc8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A and B are important for supporting the development of C.\n"
          ]
        }
      ],
      "source": [
        "input_ids = tokenizer.encode(after_ner, return_tensors='pt')\n",
        "summary_ids = model.generate(input_ids,\n",
        "            min_length = 1,\n",
        "            max_length=80,\n",
        "            num_beams=10,\n",
        "            repetition_penalty=2.5,\n",
        "            length_penalty=5.0,\n",
        "            early_stopping=True,\n",
        "            no_repeat_ngram_size=2,\n",
        "            use_cache=True,\n",
        "            do_sample = True,\n",
        "            temperature = 0.8,\n",
        "            top_k = 50,\n",
        "            top_p = 0.95)\n",
        "\n",
        "summary_text = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "print(summary_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2vfT3TO4aiOh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75zC17U2JLc9"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, PegasusForConditionalGeneration, PegasusTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sDNBhbWRVdcs"
      },
      "outputs": [],
      "source": [
        "WHITESPACE_HANDLER = lambda k: re.sub('\\s+', ' ', re.sub('\\n+', ' ', k.strip()))\n",
        "\n",
        "article_text = abstracts[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xNI2fBvxJHfw"
      },
      "outputs": [],
      "source": [
        "model_name = \"csebuetnlp/mT5_multilingual_XLSum\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgfnG2Gfb85l",
        "outputId": "ce9a0cf3-f522-4edd-f4bd-5d953e7bc4e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A review of the impact of therapeutic anticoagulation on the clinical and  тромбоtic risk of Covid-19 in patients has been published by the Royal College of Surgeons.\n"
          ]
        }
      ],
      "source": [
        "input_ids = tokenizer(\n",
        "    [WHITESPACE_HANDLER(article_text)],\n",
        "    return_tensors=\"pt\",\n",
        "    padding=\"max_length\",\n",
        "    truncation=True,\n",
        "    max_length=512\n",
        ")[\"input_ids\"]\n",
        "\n",
        "output_ids = model.generate(\n",
        "    input_ids=input_ids,\n",
        "    max_length=64,\n",
        "    no_repeat_ngram_size=2,\n",
        "    num_beams=4\n",
        ")[0]\n",
        "\n",
        "summary = tokenizer.decode(\n",
        "    output_ids,\n",
        "    skip_special_tokens=True,\n",
        "    clean_up_tokenization_spaces=False\n",
        ")\n",
        "\n",
        "print(summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WaHMcHgUd3F3"
      },
      "outputs": [],
      "source": [
        "model2_name = \"google/pegasus-xsum\"\n",
        "tokenizer2 = PegasusTokenizer.from_pretrained(model2_name)\n",
        "model2 = PegasusForConditionalGeneration.from_pretrained(model2_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvOdEoXDLMlR",
        "outputId": "ab320d2a-f3aa-434d-ecfd-d49b6672ce70"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py:1207: UserWarning: Neither `max_length` nor `max_new_tokens` have been set, `max_length` will default to 64 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  UserWarning,\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['The use of therapeutic anticoagulation may help reduce the risk of severe clinical deterioration, but its risk-benefit will be clarified in ongoing studies and meta-analyses.']"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch = tokenizer2(article_text, truncation=True, padding=\"longest\", return_tensors=\"pt\")\n",
        "translated = model2.generate(**batch)\n",
        "tgt_text = tokenizer2.batch_decode(translated, skip_special_tokens=True)\n",
        "tgt_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4f1kMm_-yuFo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Parapharser**"
      ],
      "metadata": {
        "id": "xEHCmF42WEYN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.matcher import Matcher   \n",
        "from spacy.util import filter_spans\n",
        "from transformers import PegasusForConditionalGeneration, PegasusTokenizerFast\n",
        "\n",
        "def extract_verb(text_between):\n",
        "\n",
        "  # Add pattern to matcher\n",
        "  matcher.add(\"verb-phrases\", [pattern], on_match=None)\n",
        "  doc = nlp(text_between) \n",
        "  # call the matcher to find matches \n",
        "  matches = matcher(doc) \n",
        "  if matches:\n",
        "    spans = [doc[start:end] for _, start, end in matches]\n",
        "    return filter_spans(spans)[0]\n",
        "  return ''\n",
        "\n",
        "class relation_extacctor:\n",
        "  def __init__(self, ):\n",
        "    self.matcher = self.create_matcher()\n",
        "  \n",
        "  def create_matcher(self):\n",
        "    nlp = spacy.load('en_core_sci_lg')\n",
        "    pattern=[{'POS': 'VERB', 'OP': '?'},]\n",
        "\n",
        "    # instantiate a Matcher instance\n",
        "    matcher = Matcher(nlp.vocab) \n",
        "  \n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "  \n"
      ],
      "metadata": {
        "id": "zZO-T9bwUtRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = PegasusForConditionalGeneration.from_pretrained(\"tuner007/pegasus_paraphrase\")\n",
        "tokenizer = PegasusTokenizerFast.from_pretrained(\"tuner007/pegasus_paraphrase\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3chuYa0fWKvt",
        "outputId": "b4696db8-2182-4bf3-a760-9794822bc8de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/configuration_utils.py:337: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
            "  \"Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "with open('entities_10000_docs.json') as f:\n",
        "  data = json.load(f)\n"
      ],
      "metadata": {
        "id": "HXIvZLQAW5Yk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAkFPokxXUS9",
        "outputId": "a4297b9e-ebd5-4a1b-eb3e-2582543b437d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'first_entity': 'Severe COVID-19',\n",
              "  'second_entity': 'venous thromboembolic events',\n",
              "  'sentence': 'Severe COVID-19 is associated with venous thromboembolic events and and immuno-thrombotic phenomena, responsible for pulmonary vascular damage.',\n",
              "  'text_between': ' is associated with '},\n",
              " {'first_entity': 'intermediate',\n",
              "  'second_entity': 'therapeutic-dose anticoagulation',\n",
              "  'sentence': 'This review summarizes the current knowledge on thrombotic risk in COVID-19 inpatients, the potential predictive factors (including D-dimer) and the randomized trials studying the effect of intermediate or therapeutic-dose anticoagulation on the clinical and thrombotic prognosis.',\n",
              "  'text_between': ' or '},\n",
              " {'first_entity': 'clinical prognosis',\n",
              "  'second_entity': 'standard prophylactic anticoagulation',\n",
              "  'sentence': 'Despite the initial hope, therapeutic anticoagulation does not improve the clinical prognosis in critically ill inpatients, and standard prophylactic anticoagulation is therefore recommended.',\n",
              "  'text_between': ' in critically ill inpatients, and '},\n",
              " {'first_entity': 'non-critical inpatients',\n",
              "  'second_entity': 'therapeutic anticoagulation',\n",
              "  'sentence': 'In non-critical inpatients, the use of therapeutic anticoagulation may help reduce the risk of severe clinical deterioration, but its risk-benefit will be clarified in ongoing studies and meta-analyzes.',\n",
              "  'text_between': ', the use of '}]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_paraphrased_sentences(sentence, e1, e2, num_return_sequences=10, num_beams=10, length_penalty = 0.9):\n",
        "  # tokenize the text to be form of a list of token IDs\n",
        "  inputs = tokenizer([sentence], truncation=True, padding=\"longest\", return_tensors=\"pt\")\n",
        "  # generate the paraphrased sentences\n",
        "  outputs = model.generate(\n",
        "    **inputs,\n",
        "    num_beams=num_beams,\n",
        "    num_return_sequences=num_return_sequences,\n",
        "    length_penalty = length_penalty\n",
        "  )\n",
        "  res = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "  res = [item for item in res if e1 in item and e2 in item]\n",
        "  if res:\n",
        "    res.sort(key = lambda x: len(x))\n",
        "    return res[0].replace(e1, 'first_entity').replace(e2, 'second_entity')\n",
        "  return ''\n",
        "\n",
        "\n",
        "\n",
        "def get_paraphrased_textBetween(sentence, num_return_sequences=10, num_beams=10, length_penalty = 0.8):\n",
        "  # tokenize the text to be form of a list of token IDs\n",
        "  inputs = tokenizer([sentence], truncation=True, padding=\"longest\", return_tensors=\"pt\")\n",
        "  # generate the paraphrased sentences\n",
        "  outputs = model.generate(\n",
        "    **inputs,\n",
        "    num_beams=num_beams,\n",
        "    num_return_sequences=num_return_sequences,\n",
        "    length_penalty = length_penalty\n",
        "  )\n",
        "  res = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "\n",
        "  res.sort(key = lambda x: len(x))\n",
        "  return  res[0] \n",
        "  \n"
      ],
      "metadata": {
        "id": "QfYfIbyuWe_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.matcher import Matcher   \n",
        "from spacy.util import filter_spans\n",
        "nlp = spacy.load('en_core_sci_lg')\n",
        "pattern=[{'POS': 'VERB', 'OP': '?'},]\n",
        "\n",
        "# instantiate a Matcher instance\n",
        "matcher = Matcher(nlp.vocab) \n",
        "\n",
        "def extract_verb(text_between):\n",
        "\n",
        "  # Add pattern to matcher\n",
        "  matcher.add(\"verb-phrases\", [pattern], on_match=None)\n",
        "  doc = nlp(text_between) \n",
        "  # call the matcher to find matches \n",
        "  matches = matcher(doc) \n",
        "  if matches:\n",
        "    spans = [doc[start:end] for _, start, end in matches]\n",
        "    return filter_spans(spans)[0]\n",
        "  return ''\n",
        "  "
      ],
      "metadata": {
        "id": "H4dxbRRljFq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm\n",
        "ori_sents = []\n",
        "entitesFirst = []\n",
        "entitiesSecond = []\n",
        "relation = []\n",
        "for i in tqdm(range(200)):\n",
        "  ab = data[i]\n",
        "  for ins in ab:\n",
        "    ori_sent = ins['sentence']\n",
        "    e1 = ins['first_entity']\n",
        "    e2 = ins['second_entity']\n",
        "    text_between = ins['text_between']\n",
        "    res = get_paraphrased_textBetween(text_between)\n",
        "\n",
        "    res = extract_verb(res)\n",
        "    if res:\n",
        "      ori_sents.append(ori_sent)\n",
        "      entitesFirst.append(e1)\n",
        "      entitiesSecond.append(e2)\n",
        "      relation.append(res)\n",
        "\n",
        "\n",
        "ori_sents = []\n",
        "entitesFirst = []\n",
        "entitiesSecond = []\n",
        "relation = []\n",
        "for i in tqdm(range(100)):\n",
        "  ab = data[i]\n",
        "  for ins in ab:\n",
        "    ori_sent = ins['sentence']\n",
        "    e1 = ins['first_entity']\n",
        "    e2 = ins['second_entity']\n",
        "    text_between = ins['text_between']\n",
        "    sent = ' '.join([e1, text_between, e2])\n",
        "    res = get_paraphrased_textBetween(sent)\n",
        "    res = extract_verb(res)\n",
        "    if res:\n",
        "      ori_sents.append(ori_sent)\n",
        "      entitesFirst.append(e1)\n",
        "      entitiesSecond.append(e2)\n",
        "      relation.append(res)\n",
        "\n",
        "ori_sents = []\n",
        "entitesFirst = []\n",
        "entitiesSecond = []\n",
        "relation = []\n",
        "for i in tqdm(range(200)):\n",
        "  ab = data[i]\n",
        "  for ins in ab:\n",
        "    ori_sent = ins['sentence']\n",
        "    e1 = ins['first_entity']\n",
        "    e2 = ins['second_entity']\n",
        "    text_between = ins['text_between']\n",
        "    res = extract_verb(text_between)\n",
        "    if res:\n",
        "      ori_sents.append(ori_sent)\n",
        "      entitesFirst.append(e1)\n",
        "      entitiesSecond.append(e2)\n",
        "      relation.append(res)\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "6ada5b427290462ca0abb4461107537a",
            "270f0c1a29c6470ba771c74c41048506",
            "1d97f8ef12e84f2084d75bc01a9a57d7",
            "a21bd192e8514638b25fece1dee265e2",
            "0a51a5cd5e7248a78e1ce8e3f90f05f4",
            "98adf8b9ca474bbcb03aa9aeebc9a5ce",
            "32a5551dd82940f1aa6caed53b8b90ab",
            "1af0080d371e4010a6c8701631dd68bd",
            "8a269c8133b240a7bb0a971a30f6653d",
            "d75c5afcd79345c3a5053676c798095a",
            "27a66e66ab564e4988269a9334f615dd"
          ]
        },
        "id": "cPVV1JN8Ykzm",
        "outputId": "363a0346-f81f-43ee-e023-265597412763"
      },
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6ada5b427290462ca0abb4461107537a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/200 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "4YC9-Go23GIo",
        "outputId": "bd3b7574-88b7-4708-e1e2-b1f0246ffce3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nOnly perserve text between two entities\\nFiliter the instances which the length of the in-between text \\nis too short compared to the original sentence\\nParapharse the text with beam search (width = 10) using length penelty (0.9)\\nSelect the shortest output.\\nExtract the verb from the output\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "'''\n",
        "Only perserve text between two entities\n",
        "Filiter the instances which the length of the in-between text \n",
        "is too short compared to the original sentence\n",
        "Parapharse the text with beam search (width = 10) using length penelty (0.9)\n",
        "Select the shortest output.\n",
        "Extract the verb from the output\n",
        "'''\n",
        "\n",
        "df = pd.DataFrame({'sentence': ori_sents, 'entity_1':entitesFirst, 'entity_2':entitiesSecond, 'relationship':relation})"
      ],
      "metadata": {
        "id": "qZ0MzdTbcDF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "raKorx389Xzt",
        "outputId": "8e596f11-8cb9-4a0d-bf00-39ebbf182b9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b4b71ca2-cdec-4bae-a447-53e29799732d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>entity_1</th>\n",
              "      <th>entity_2</th>\n",
              "      <th>relationship</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The shortening of hospital stays implies rethi...</td>\n",
              "      <td>hospital stays</td>\n",
              "      <td>limb arthroplasty</td>\n",
              "      <td>(means)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\\n\\n\\nMETHODS\\nMedical costs associated with C...</td>\n",
              "      <td>complications</td>\n",
              "      <td>medical costs</td>\n",
              "      <td>(used)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The FINE-CKD model allows for reliable assessm...</td>\n",
              "      <td>benefits and costs</td>\n",
              "      <td>cost-effectiveness</td>\n",
              "      <td>(used)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Here, using the same approaches, we show that ...</td>\n",
              "      <td>hemin</td>\n",
              "      <td>siderophores</td>\n",
              "      <td>(repressed)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Moreover, the presence of both hemin and a xen...</td>\n",
              "      <td>xenosiderophore</td>\n",
              "      <td>Hxu systems</td>\n",
              "      <td>(affected)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>The primary outcome was the change in Minnesot...</td>\n",
              "      <td>primary outcome</td>\n",
              "      <td>baseline</td>\n",
              "      <td>(Living)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>To overcome such barriers, additional app-trai...</td>\n",
              "      <td>instruction manual</td>\n",
              "      <td>trial period</td>\n",
              "      <td>(included)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>Among females, social norm information showed ...</td>\n",
              "      <td>social norm information</td>\n",
              "      <td>backfire effect</td>\n",
              "      <td>(showed)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>BACKGROUND\\nAdequately measuring resilience is...</td>\n",
              "      <td>resilience</td>\n",
              "      <td>resources through social work</td>\n",
              "      <td>(support)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>A widely accepted measure of youth resilience ...</td>\n",
              "      <td>youth resilience</td>\n",
              "      <td>vulnerable youth</td>\n",
              "      <td>(shown)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>92 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b4b71ca2-cdec-4bae-a447-53e29799732d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b4b71ca2-cdec-4bae-a447-53e29799732d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b4b71ca2-cdec-4bae-a447-53e29799732d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                             sentence  ... relationship\n",
              "0   The shortening of hospital stays implies rethi...  ...      (means)\n",
              "1   \\n\\n\\nMETHODS\\nMedical costs associated with C...  ...       (used)\n",
              "2   The FINE-CKD model allows for reliable assessm...  ...       (used)\n",
              "3   Here, using the same approaches, we show that ...  ...  (repressed)\n",
              "4   Moreover, the presence of both hemin and a xen...  ...   (affected)\n",
              "..                                                ...  ...          ...\n",
              "87  The primary outcome was the change in Minnesot...  ...     (Living)\n",
              "88  To overcome such barriers, additional app-trai...  ...   (included)\n",
              "89  Among females, social norm information showed ...  ...     (showed)\n",
              "90  BACKGROUND\\nAdequately measuring resilience is...  ...    (support)\n",
              "91  A widely accepted measure of youth resilience ...  ...      (shown)\n",
              "\n",
              "[92 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('filiter_by_len_result.csv')"
      ],
      "metadata": {
        "id": "6HxHnAixz5FV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.verb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "5JlXOoSK9RfZ",
        "outputId": "531b8a0c-88e5-4b94-dfa8-d1a33604c806"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-9d9fb41b-73ac-4d2a-9019-5253fef51a83\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>sentence</th>\n",
              "      <th>entity_1</th>\n",
              "      <th>entity_2</th>\n",
              "      <th>relationship</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Severe COVID-19 is associated with venous thro...</td>\n",
              "      <td>Severe COVID-19</td>\n",
              "      <td>venous thromboembolic events</td>\n",
              "      <td>associated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>The shortening of hospital stays implies rethi...</td>\n",
              "      <td>hospital stays</td>\n",
              "      <td>limb arthroplasty</td>\n",
              "      <td>implies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Optimal preparation of the patient and anticip...</td>\n",
              "      <td>postoperative process</td>\n",
              "      <td>safety and patient satisfaction</td>\n",
              "      <td>limit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>However, patient-centred information and educa...</td>\n",
              "      <td>patient-centred information and education</td>\n",
              "      <td>complicated postoperative outcomes</td>\n",
              "      <td>recommended</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>OBJECTIVES\\nMany patients with type 2 diabetes...</td>\n",
              "      <td>delay in treatment</td>\n",
              "      <td>treatment with guideline-recommended angiotens...</td>\n",
              "      <td>fail</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>612</th>\n",
              "      <td>612</td>\n",
              "      <td>However, this method is time consuming and, wh...</td>\n",
              "      <td>time consuming</td>\n",
              "      <td>pupils</td>\n",
              "      <td>faced</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>613</th>\n",
              "      <td>613</td>\n",
              "      <td>This study assesses app software with a built-...</td>\n",
              "      <td>built-in avatar</td>\n",
              "      <td>young persons</td>\n",
              "      <td>guide</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>614</th>\n",
              "      <td>614</td>\n",
              "      <td>A confirmatory factor analysis supported the 3...</td>\n",
              "      <td>confirmatory factor analysis</td>\n",
              "      <td>3-factor solution</td>\n",
              "      <td>supported</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>615</th>\n",
              "      <td>615</td>\n",
              "      <td>\\n\\n\\nCONCLUSIONS\\nALEX, an avatar with an int...</td>\n",
              "      <td>integrated voice guide</td>\n",
              "      <td>resilience</td>\n",
              "      <td>measuring</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>616</th>\n",
              "      <td>616</td>\n",
              "      <td>The CFA reports similar structure using the av...</td>\n",
              "      <td>avatar</td>\n",
              "      <td>original validation</td>\n",
              "      <td>compared</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>617 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9d9fb41b-73ac-4d2a-9019-5253fef51a83')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9d9fb41b-73ac-4d2a-9019-5253fef51a83 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9d9fb41b-73ac-4d2a-9019-5253fef51a83');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     Unnamed: 0  ... relationship\n",
              "0             0  ...   associated\n",
              "1             1  ...      implies\n",
              "2             2  ...        limit\n",
              "3             3  ...  recommended\n",
              "4             4  ...         fail\n",
              "..          ...  ...          ...\n",
              "612         612  ...        faced\n",
              "613         613  ...        guide\n",
              "614         614  ...    supported\n",
              "615         615  ...    measuring\n",
              "616         616  ...     compared\n",
              "\n",
              "[617 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_re"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "CiEIJwfs9ts9",
        "outputId": "7b5f387b-96a4-47e7-fb6a-b93253ac0527"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e5f982ee-2447-4955-99e4-c511ffe9ffec\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>entity_1</th>\n",
              "      <th>entity_2</th>\n",
              "      <th>relationship</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Severe COVID-19 is associated with venous thro...</td>\n",
              "      <td>Severe COVID-19</td>\n",
              "      <td>venous thromboembolic events</td>\n",
              "      <td>associated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The shortening of hospital stays implies rethi...</td>\n",
              "      <td>hospital stays</td>\n",
              "      <td>limb arthroplasty</td>\n",
              "      <td>stays</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Optimal preparation of the patient and anticip...</td>\n",
              "      <td>postoperative process</td>\n",
              "      <td>safety and patient satisfaction</td>\n",
              "      <td>limit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>OBJECTIVES\\nMany patients with type 2 diabetes...</td>\n",
              "      <td>delay in treatment</td>\n",
              "      <td>treatment with guideline-recommended angiotens...</td>\n",
              "      <td>fail</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\\n\\n\\nSTUDY DESIGN\\nRetrospective analysis usi...</td>\n",
              "      <td>Retrospective analysis</td>\n",
              "      <td>administrative claims database</td>\n",
              "      <td>using</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>194</th>\n",
              "      <td>This article describes the reshaping of the NH...</td>\n",
              "      <td>data collection</td>\n",
              "      <td>COVID-19 pandemic</td>\n",
              "      <td>collected</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>During the COVID-19 pandemic, the Health Depar...</td>\n",
              "      <td>COVID-19 pandemic</td>\n",
              "      <td>surveys and developed new ones</td>\n",
              "      <td>developed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>In addition, 7 Health Opinion Polls were condu...</td>\n",
              "      <td>COVID-19-related knowledge</td>\n",
              "      <td>vaccine intentions</td>\n",
              "      <td>include</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>Large national health surveys have always bala...</td>\n",
              "      <td>national health surveys</td>\n",
              "      <td>quality dimensions</td>\n",
              "      <td>balanced</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>The COVID-19 pandemic shifted these balances, ...</td>\n",
              "      <td>COVID-19 pandemic</td>\n",
              "      <td>health data</td>\n",
              "      <td>disrupted</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>199 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e5f982ee-2447-4955-99e4-c511ffe9ffec')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e5f982ee-2447-4955-99e4-c511ffe9ffec button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e5f982ee-2447-4955-99e4-c511ffe9ffec');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                              sentence  ... relationship\n",
              "0    Severe COVID-19 is associated with venous thro...  ...   associated\n",
              "1    The shortening of hospital stays implies rethi...  ...        stays\n",
              "2    Optimal preparation of the patient and anticip...  ...        limit\n",
              "3    OBJECTIVES\\nMany patients with type 2 diabetes...  ...         fail\n",
              "4    \\n\\n\\nSTUDY DESIGN\\nRetrospective analysis usi...  ...        using\n",
              "..                                                 ...  ...          ...\n",
              "194  This article describes the reshaping of the NH...  ...    collected\n",
              "195  During the COVID-19 pandemic, the Health Depar...  ...    developed\n",
              "196  In addition, 7 Health Opinion Polls were condu...  ...      include\n",
              "197  Large national health surveys have always bala...  ...     balanced\n",
              "198  The COVID-19 pandemic shifted these balances, ...  ...    disrupted\n",
              "\n",
              "[199 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_verb = df_verb.rename(columns={\"relationship\": \"verb\"})"
      ],
      "metadata": {
        "id": "uuaS82OT-Nhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2 df have diff length, more strict rules applied to paraphraser\n",
        "df2 = df_re.merge(df_verb, on = ['sentence', 'entity_1', 'entity_2'])\n",
        "df2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "1GqItxX1_Guz",
        "outputId": "343534a5-1158-43fe-887a-a322a1dcc13b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5b3d5b00-eea1-4528-86b4-41fbf37bf3ef\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>entity_1</th>\n",
              "      <th>entity_2</th>\n",
              "      <th>relationship</th>\n",
              "      <th>verb</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Severe COVID-19 is associated with venous thro...</td>\n",
              "      <td>Severe COVID-19</td>\n",
              "      <td>venous thromboembolic events</td>\n",
              "      <td>associated</td>\n",
              "      <td>associated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The shortening of hospital stays implies rethi...</td>\n",
              "      <td>hospital stays</td>\n",
              "      <td>limb arthroplasty</td>\n",
              "      <td>stays</td>\n",
              "      <td>implies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Optimal preparation of the patient and anticip...</td>\n",
              "      <td>postoperative process</td>\n",
              "      <td>safety and patient satisfaction</td>\n",
              "      <td>limit</td>\n",
              "      <td>limit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>OBJECTIVES\\nMany patients with type 2 diabetes...</td>\n",
              "      <td>delay in treatment</td>\n",
              "      <td>treatment with guideline-recommended angiotens...</td>\n",
              "      <td>fail</td>\n",
              "      <td>fail</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\\n\\n\\nSTUDY DESIGN\\nRetrospective analysis usi...</td>\n",
              "      <td>Retrospective analysis</td>\n",
              "      <td>administrative claims database</td>\n",
              "      <td>using</td>\n",
              "      <td>using</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>Because of the COVID-19 pandemic, NHANES data ...</td>\n",
              "      <td>COVID-19 pandemic</td>\n",
              "      <td>year gap in data collection</td>\n",
              "      <td>suspended</td>\n",
              "      <td>suspended</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>During the COVID-19 pandemic, the Health Depar...</td>\n",
              "      <td>COVID-19 pandemic</td>\n",
              "      <td>surveys and developed new ones</td>\n",
              "      <td>developed</td>\n",
              "      <td>adjusted</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>In addition, 7 Health Opinion Polls were condu...</td>\n",
              "      <td>COVID-19-related knowledge</td>\n",
              "      <td>vaccine intentions</td>\n",
              "      <td>include</td>\n",
              "      <td>including</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>Large national health surveys have always bala...</td>\n",
              "      <td>national health surveys</td>\n",
              "      <td>quality dimensions</td>\n",
              "      <td>balanced</td>\n",
              "      <td>balanced</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>The COVID-19 pandemic shifted these balances, ...</td>\n",
              "      <td>COVID-19 pandemic</td>\n",
              "      <td>health data</td>\n",
              "      <td>disrupted</td>\n",
              "      <td>shifted</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>177 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5b3d5b00-eea1-4528-86b4-41fbf37bf3ef')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5b3d5b00-eea1-4528-86b4-41fbf37bf3ef button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5b3d5b00-eea1-4528-86b4-41fbf37bf3ef');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                              sentence  ...        verb\n",
              "0    Severe COVID-19 is associated with venous thro...  ...  associated\n",
              "1    The shortening of hospital stays implies rethi...  ...     implies\n",
              "2    Optimal preparation of the patient and anticip...  ...       limit\n",
              "3    OBJECTIVES\\nMany patients with type 2 diabetes...  ...        fail\n",
              "4    \\n\\n\\nSTUDY DESIGN\\nRetrospective analysis usi...  ...       using\n",
              "..                                                 ...  ...         ...\n",
              "172  Because of the COVID-19 pandemic, NHANES data ...  ...   suspended\n",
              "173  During the COVID-19 pandemic, the Health Depar...  ...    adjusted\n",
              "174  In addition, 7 Health Opinion Polls were condu...  ...   including\n",
              "175  Large national health surveys have always bala...  ...    balanced\n",
              "176  The COVID-19 pandemic shifted these balances, ...  ...     shifted\n",
              "\n",
              "[177 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2[\"relationship_l\"] = df2.relationship.apply(lemmatize)\n",
        "df2[\"verb_l\"] = df2.verb.apply(lemmatize)"
      ],
      "metadata": {
        "id": "MudaTTlSAGrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diff = df2[df2.relationship_l != df2.verb_l]"
      ],
      "metadata": {
        "id": "_NcusOVEAXXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diff"
      ],
      "metadata": {
        "id": "CHTQjk7jCuOQ",
        "outputId": "37bb7c1b-a696-4978-ceed-610d14cea77c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 752
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5ed79cf8-122a-4e4f-b562-10c6bc516644\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>entity_1</th>\n",
              "      <th>entity_2</th>\n",
              "      <th>relationship</th>\n",
              "      <th>verb</th>\n",
              "      <th>relationship_l</th>\n",
              "      <th>verb_l</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The shortening of hospital stays implies rethinking the pre- and post-operative management of lower limb arthroplasty.</td>\n",
              "      <td>hospital stays</td>\n",
              "      <td>limb arthroplasty</td>\n",
              "      <td>stays</td>\n",
              "      <td>implies</td>\n",
              "      <td>stay</td>\n",
              "      <td>imply</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>\\n\\n\\nMETHODS\\nMedical costs associated with CKD management, renal replacement therapies (RRTs), major CKD complications (eg, myocardial infarction, stroke, heart failure, atrial fibrillation, and hyperkalemia), and death were estimated using generalized estimating equations adjusting for baseline demographics, complications, and medical costs.</td>\n",
              "      <td>complications</td>\n",
              "      <td>medical costs</td>\n",
              "      <td>used</td>\n",
              "      <td>estimated</td>\n",
              "      <td>use</td>\n",
              "      <td>estimate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Nanocrystal surfaces are commonly populated by organic ligands, which play a determining role in the optical, electronic, thermal, and catalytic properties of the individual nanocrystals and their assemblies.</td>\n",
              "      <td>Nanocrystal surfaces</td>\n",
              "      <td>organic ligands</td>\n",
              "      <td>found</td>\n",
              "      <td>populated</td>\n",
              "      <td>find</td>\n",
              "      <td>populate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>We determine, for example, that dithiols which link facets of neighboring nanocrystals only exhibit uniaxial rotation and that longer ligands have higher activation energies and show smaller opening angles of precession due to stronger ligand-ligand interactions.</td>\n",
              "      <td>neighboring nanocrystals</td>\n",
              "      <td>uniaxial rotation and that longer ligands</td>\n",
              "      <td>shown</td>\n",
              "      <td>exhibit</td>\n",
              "      <td>show</td>\n",
              "      <td>exhibit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Here, using the same approaches, we show that physiological concentrations of hemin in the bacterial growth medium result in the repression of the expression of the proteins of the PVD- and PCH-dependent iron uptake pathways, leading to less production of these two siderophores.</td>\n",
              "      <td>hemin</td>\n",
              "      <td>siderophores</td>\n",
              "      <td>caused</td>\n",
              "      <td>result</td>\n",
              "      <td>cause</td>\n",
              "      <td>result</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165</th>\n",
              "      <td>To understand the miRNA targets contributing to this activity, we performed Ago PAR-CLIP analysis on EBV-positive, reactivated Burkitt's lymphoma cells and identified multiple miR-BHRF1-3 interactions with viral transcripts.</td>\n",
              "      <td>Ago PAR-CLIP analysis</td>\n",
              "      <td>interactions with viral transcripts</td>\n",
              "      <td>identified</td>\n",
              "      <td>reactivated</td>\n",
              "      <td>identify</td>\n",
              "      <td>reactivate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>169</th>\n",
              "      <td>Here, we demonstrate that EBV miR-BHRF1-3 can suppress lytic replication by directly inhibiting Zta expression.</td>\n",
              "      <td>lytic replication</td>\n",
              "      <td>Zta expression</td>\n",
              "      <td>blocking</td>\n",
              "      <td>inhibiting</td>\n",
              "      <td>block</td>\n",
              "      <td>inhibit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>170</th>\n",
              "      <td>With the global rise of COVID-19 in early 2020, the NCHS mobilized to rapidly respond to the growing need for reliable, accurate, and complete real-time data on COVID-19 deaths.</td>\n",
              "      <td>COVID-19</td>\n",
              "      <td>COVID-19 deaths</td>\n",
              "      <td>grew</td>\n",
              "      <td>mobilized</td>\n",
              "      <td>grow</td>\n",
              "      <td>mobilize</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>During the COVID-19 pandemic, the Health Department adjusted existing surveys and developed new ones to improve our understanding of the impact of the pandemic on physical health, mental health, and social determinants of health and to incorporate more explicit measures of racial inequities.</td>\n",
              "      <td>COVID-19 pandemic</td>\n",
              "      <td>surveys and developed new ones</td>\n",
              "      <td>developed</td>\n",
              "      <td>adjusted</td>\n",
              "      <td>develop</td>\n",
              "      <td>adjust</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>The COVID-19 pandemic shifted these balances, with both disrupted survey operations and a critical need for relevant and timely health data for decision-making.</td>\n",
              "      <td>COVID-19 pandemic</td>\n",
              "      <td>health data</td>\n",
              "      <td>disrupted</td>\n",
              "      <td>shifted</td>\n",
              "      <td>disrupt</td>\n",
              "      <td>shift</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>62 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5ed79cf8-122a-4e4f-b562-10c6bc516644')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5ed79cf8-122a-4e4f-b562-10c6bc516644 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5ed79cf8-122a-4e4f-b562-10c6bc516644');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                                                                                                                                                                                                                                                                                                                       sentence  ...      verb_l\n",
              "1                                                                                                                                                                                                                                        The shortening of hospital stays implies rethinking the pre- and post-operative management of lower limb arthroplasty.  ...       imply\n",
              "7    \\n\\n\\nMETHODS\\nMedical costs associated with CKD management, renal replacement therapies (RRTs), major CKD complications (eg, myocardial infarction, stroke, heart failure, atrial fibrillation, and hyperkalemia), and death were estimated using generalized estimating equations adjusting for baseline demographics, complications, and medical costs.  ...    estimate\n",
              "9                                                                                                                                              Nanocrystal surfaces are commonly populated by organic ligands, which play a determining role in the optical, electronic, thermal, and catalytic properties of the individual nanocrystals and their assemblies.  ...    populate\n",
              "12                                                                                      We determine, for example, that dithiols which link facets of neighboring nanocrystals only exhibit uniaxial rotation and that longer ligands have higher activation energies and show smaller opening angles of precession due to stronger ligand-ligand interactions.  ...     exhibit\n",
              "15                                                                      Here, using the same approaches, we show that physiological concentrations of hemin in the bacterial growth medium result in the repression of the expression of the proteins of the PVD- and PCH-dependent iron uptake pathways, leading to less production of these two siderophores.  ...      result\n",
              "..                                                                                                                                                                                                                                                                                                                                                          ...  ...         ...\n",
              "165                                                                                                                            To understand the miRNA targets contributing to this activity, we performed Ago PAR-CLIP analysis on EBV-positive, reactivated Burkitt's lymphoma cells and identified multiple miR-BHRF1-3 interactions with viral transcripts.  ...  reactivate\n",
              "169                                                                                                                                                                                                                                             Here, we demonstrate that EBV miR-BHRF1-3 can suppress lytic replication by directly inhibiting Zta expression.  ...     inhibit\n",
              "170                                                                                                                                                                           With the global rise of COVID-19 in early 2020, the NCHS mobilized to rapidly respond to the growing need for reliable, accurate, and complete real-time data on COVID-19 deaths.  ...    mobilize\n",
              "173                                                        During the COVID-19 pandemic, the Health Department adjusted existing surveys and developed new ones to improve our understanding of the impact of the pandemic on physical health, mental health, and social determinants of health and to incorporate more explicit measures of racial inequities.  ...      adjust\n",
              "176                                                                                                                                                                                            The COVID-19 pandemic shifted these balances, with both disrupted survey operations and a critical need for relevant and timely health data for decision-making.  ...       shift\n",
              "\n",
              "[62 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('max_colwidth', 400)\n",
        "diff.to_csv('comparison.csv')"
      ],
      "metadata": {
        "id": "urVy_khTBogn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7o18t3vyugz"
      },
      "source": [
        "**word2vec**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_ZvedEpyxq9"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "import pandas as pd\n",
        "from gensim.models import word2vec\n",
        "import gensim.downloader as api\n",
        "import numpy as np\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from scipy.cluster.hierarchy import dendrogram\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "import pickle\n",
        "from sklearn.metrics import silhouette_samples, silhouette_score\n",
        "from matplotlib.pyplot import figure\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_pickle(model, filename):\n",
        "    with open(filename, 'wb') as f:\n",
        "        pickle.dump(model, f)\n",
        "def load_pickle(filename):\n",
        "    with open(filename, 'rb') as f:\n",
        "        return pickle.load(f)"
      ],
      "metadata": {
        "id": "QLq_LYCWE4Hg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download google negative 300 word2vec pretraiend embeddings\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://drive.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://drive.google.com/uc?export=download&id=0B7XkCwpI5KDYNlNUTTlSS21pQmM' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=0B7XkCwpI5KDYNlNUTTlSS21pQmM\" -O GoogleNews-vectors-negative300.bin.gz && rm -rf /tmp/cookies.txt"
      ],
      "metadata": {
        "id": "Lh0dwYXdbltp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glove_model = gensim.downloader.load(\"glove-wiki-gigaword-100\")  "
      ],
      "metadata": {
        "id": "PcazKhUR0y8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2vec_model = gensim.models.KeyedVectors.load_word2vec_format(\"GoogleNews-vectors-negative300.bin.gz\", binary=True)"
      ],
      "metadata": {
        "id": "f5pIIj_VcqyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1000 abstracts\n",
        "df_verb = pd.read_csv(\"direct_verb.csv\")\n",
        "# 10000 abstracts\n",
        "df_re = pd.read_csv(\"relationship_10000.csv\")"
      ],
      "metadata": {
        "id": "Puh5D8f7T89I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KOQdz2_hIm5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aFBYFfdMaltI"
      },
      "outputs": [],
      "source": [
        "class Checker():\n",
        "  def __init__(self, model, corpus):\n",
        "    self.cnt = 0\n",
        "    self.model = model\n",
        "    cnt = 0\n",
        "    for word in corpus:\n",
        "      if self.checkEmbedding(word):\n",
        "        print(f\"'{word : <32}'\", end = \"       \")\n",
        "        cnt += 1\n",
        "        if not cnt % 5:\n",
        "          print()\n",
        "    print(\"\\n\")\n",
        "    print(f\"Total number of words not in dictionary is {cnt}.\")\n",
        "  def checkEmbedding(self, sent):\n",
        "    sent = sent.split()\n",
        "    n = len(self.model[\"as\"])\n",
        "    sent_vec = np.zeros(n)\n",
        "    word_cnt = 0\n",
        "    for word in sent:\n",
        "      if word in self.model:\n",
        "        sent_vec += self.model[word]\n",
        "        word_cnt += 1\n",
        "    if word_cnt == 0:\n",
        "      self.cnt += 1\n",
        "      return True\n",
        "    else:\n",
        "      return False\n",
        "\n",
        "class Clustering():\n",
        "  def __init__(self, model):\n",
        "    self.model = model\n",
        "    self.lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "  def lemmatize(self, s):\n",
        "    token_words = word_tokenize(s)\n",
        "    word_list = [self.lemmatizer.lemmatize(word.lower(),'v') for word in token_words]\n",
        "    return \" \".join((word_list))\n",
        "\n",
        "  def getEmbedding(self, sent):\n",
        "    sent = sent.split()\n",
        "    n = len(self.model[\"as\"])\n",
        "    sent_vec = np.zeros(n)\n",
        "    word_cnt = 0\n",
        "    for word in sent:\n",
        "      if word in self.model:\n",
        "        sent_vec += self.model[word]\n",
        "        word_cnt += 1\n",
        "    if word_cnt != 0:\n",
        "      sent_vec /= word_cnt \n",
        "    return sent_vec\n",
        "\n",
        "  def get_cluster_word(self, df, threshold):\n",
        "    def get_cluster_word(embed):\n",
        "      return self.model.similar_by_vector(embed)[0][0]\n",
        "\n",
        "    print(\"*\"*200)\n",
        "    print(f\"Total input length: {len(df)}\")\n",
        "    print(\"*\"*200)\n",
        "    dfToReturn = df.copy()\n",
        "\n",
        "    # Lemmatize\n",
        "    dfToReturn[\"relationship_lem\"] = dfToReturn.relationship.apply(self.lemmatize)\n",
        "    print(\"Finished lemmatizing, checking words not in model vocabulary: \\n\")\n",
        "    Checker(self.model, dfToReturn.relationship_lem)\n",
        "    print(\"*\"*200)\n",
        "\n",
        "    # Get embedding for each word\n",
        "    dfToReturn[\"embedding\"] = dfToReturn.relationship_lem.apply(self.getEmbedding)\n",
        "    print(\"Finished creating embeddings\")\n",
        "    \n",
        "    # Extract valid embeddings for clustering, invalid embeddings are 0 everywhere\n",
        "    validEmbeddings = dfToReturn[dfToReturn.embedding.apply(lambda x : np.any(x))].embedding\n",
        "    print(f\"Valid words count: {len(validEmbeddings)}\")\n",
        "    print(\"*\"*200)\n",
        "\n",
        "    # Use AgglomerativeClustering on valid embeddings\n",
        "    print(\"Start clustering\")\n",
        "    agg = AgglomerativeClustering(n_clusters = None, affinity= \"cosine\", linkage = \"complete\", distance_threshold = threshold).fit((np.array(list(validEmbeddings))))\n",
        "    print(\"Finished clustering\")\n",
        "    print(f\"Cluster centers count: {agg.n_clusters_}    with threshold of {threshold}\")\n",
        "    print(\"*\"*200)\n",
        "\n",
        "    # Assign cluster centers accordingly\n",
        "    dfToReturn[\"cluster\"] = pd.DataFrame(agg.labels_, index = validEmbeddings.index)\n",
        "\n",
        "    # Calculate average word2vec for each clusters\n",
        "    cluster_embedding = pd.DataFrame(dfToReturn.groupby(\"cluster\").embedding.apply(np.mean)).reset_index()\n",
        "\n",
        "    # Infer the cluster word from the most similar vectors approach\n",
        "    print(\"Start inferencing cluster center word\")\n",
        "    cluster_embedding[\"cluster_word\"] = cluster_embedding.embedding.apply(get_cluster_word)\n",
        "    print(\"Finished inferencing cluster center word\")\n",
        "    print(\"*\"*200)\n",
        "    \n",
        "    # Plot the dendrogram plot (optional)\n",
        "    figure(figsize=(10, 8), dpi=80)\n",
        "    self.plot_dendrogram(agg, labels = list(df.relationship), leaf_font_size=10, orientation = 'right')\n",
        "    plt.axvline(x = threshold, color = 'r', linestyle = 'dashed')\n",
        "\n",
        "\n",
        "    # Merge to return the final output dataframe\n",
        "    return dfToReturn.merge(cluster_embedding[[\"cluster\", \"cluster_word\"]], on = [\"cluster\"], how = \"left\")\n",
        "\n",
        "  def plot_dendrogram(self, agg_model, **kwargs):\n",
        "    # Create linkage matrix and then plot the dendrogram\n",
        "\n",
        "    # create the counts of samples under each node\n",
        "    model = agg_model\n",
        "    counts = np.zeros(model.children_.shape[0])\n",
        "    n_samples = len(model.labels_)\n",
        "    for i, merge in enumerate(model.children_):\n",
        "        current_count = 0\n",
        "        for child_idx in merge:\n",
        "            if child_idx < n_samples:\n",
        "                current_count += 1  # leaf node\n",
        "            else:\n",
        "                current_count += counts[child_idx - n_samples]\n",
        "        counts[i] = current_count\n",
        "\n",
        "    linkage_matrix = np.column_stack(\n",
        "        [model.children_, model.distances_, counts]\n",
        "    ).astype(float)\n",
        "\n",
        "    # Plot the corresponding dendrogram\n",
        "    dendrogram(linkage_matrix, **kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c = Clustering(word2vec_model)\n",
        "word2vec_result_1000 = c.get_cluster_word(df_verb, 0.9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4t-IFCiW5X0e",
        "outputId": "8ff83b62-ee13-4451-faa4-18c541ea779f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************************************************************************************************************************************************************************************************\n",
            "Total input length: 617\n",
            "********************************************************************************************************************************************************************************************************\n",
            "Finished lemmatizing, checking words not in model vocabulary: \n",
            "\n",
            "'west-single-point               '       'dropcasted                      '       'catalyse                        '       'catalyse                        '       'analyse                         '       \n",
            "'extravasate                     '       'practise                        '       \n",
            "\n",
            "Total number of words not in dictionary is 7.\n",
            "********************************************************************************************************************************************************************************************************\n",
            "Finished creating embeddings\n",
            "Valid words count: 610\n",
            "********************************************************************************************************************************************************************************************************\n",
            "Start clustering\n",
            "Finished clustering\n",
            "Cluster centers count: 39    with threshold of 0.9\n",
            "********************************************************************************************************************************************************************************************************\n",
            "Start inferencing cluster center word\n",
            "Finished inferencing cluster center word\n",
            "********************************************************************************************************************************************************************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = word2vec_result_1000[~word2vec_result_1000.cluster.isnull()]"
      ],
      "metadata": {
        "id": "s1ih6IyW6F4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "silhouette_score(list(word2vec_result_1000.embedding.dropna()), list(word2vec_result_1000.cluster))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "Bhjjzpka5poD",
        "outputId": "b7c90b93-19ae-432b-8b23-ed738256f0ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-99ebceb791ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msilhouette_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword2vec_result_1000\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword2vec_result_1000\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_unsupervised.py\u001b[0m in \u001b[0;36msilhouette_score\u001b[0;34m(X, labels, metric, sample_size, random_state, **kwds)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msilhouette_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/cluster/_unsupervised.py\u001b[0m in \u001b[0;36msilhouette_samples\u001b[0;34m(X, labels, metric, **kwds)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \"\"\"\n\u001b[0;32m--> 213\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;31m# Check for non-zero diagonal entries in precomputed distance matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    759\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m         \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'O'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m     58\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                     (type_err,\n\u001b[0;32m---> 60\u001b[0;31m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[1;32m     61\u001b[0m             )\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c = Clustering(glove_model)\n",
        "glove_result_re = c.get_cluster_word(df_re, 0.7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gd8KKitwf05V",
        "outputId": "6bf49441-cbbf-4059-fcd9-b6fab4e0e0fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************************************************************************************************************************************************************************************************\n",
            "Total input length: 34772\n",
            "********************************************************************************************************************************************************************************************************\n",
            "Finished lemmatizing, checking words not in model vocabulary: \n",
            "\n",
            "'west-single-point               '       'dropcasted                      '       '°                               '       'extravasate                     '       'self-scheduled                  '       \n",
            "'´                               '       '´                               '       'downregulating                  '       'subserve                        '       'co-deliver                      '       \n",
            "'co-deliver                      '       'recategorising                  '       '≥3.70                           '       'randomise                       '       'randomise                       '       \n",
            "'tphp-polluted                   '       'chemisorb                       '       'synthetized                     '       'mineralize                      '       'acetylate                       '       \n",
            "'doliiform                       '       'reisolated                      '       'downregulating                  '       'stimulate/alter                 '       'hypomethylated                  '       \n",
            "'hypomethylated                  '       'hypomethylated                  '       'randomise                       '       'hospitalise                     '       'randomise                       '       \n",
            "'randomise                       '       'dysregulated                    '       'receinving                      '       'dialternating                   '       'solubilize                      '       \n",
            "'×                               '       'cross-compared                  '       'subclassified                   '       'de-correlate                    '       'phenotyped                      '       \n",
            "'downregulating                  '       'dedifferentiate                 '       'co-expressed                    '       'maf/nr1h3-expressing            '       'proning                         '       \n",
            "'downregulating                  '       '∗                               '       'contraindicate                  '       'disilaborirenes                 '       'intercalate                     '       \n",
            "'preexist                        '       '99mtc-labeled                   '       'ubiquitinates                   '       'anticoagulated                  '       'failure/left                    '       \n",
            "'co-cultured                     '       'vaping                          '       '°                               '       'disbud                          '       'self-evolve                     '       \n",
            "'dpg-based                       '       'vdw-based                       '       'semistructured                  '       'coexpressed                     '       'co-localize                     '       \n",
            "'2.81±2.73                       '       'resect                          '       'dichotomize                     '       'upregulating                    '       'genotyped                       '       \n",
            "'photogenerated                  '       'photoactivated                  '       'deselect                        '       'administration-approved         '       'resynthesize                    '       \n",
            "'esplénico                       '       'seguida                         '       'demostró                        '       'temprana                        '       'sometidos                       '       \n",
            "'elegibles                       '       'pedicled                        '       'recode                          '       'anonymised                      '       'resect                          '       \n",
            "'nebulized                       '       'upregulating                    '       'fractionate                     '       '≥61                             '       'cotesting                       '       \n",
            "'benzoides                       '       'functionalize                   '       'degrease                        '       'acetylate                       '       'downregulating                  '       \n",
            "'deacetylated                    '       're-categorizes                  '       'traduce                         '       'imidized                        '       'esterify                        '       \n",
            "'nau-nbt                         '       'time-determined                 '       'gisevii                         '       'demethylate                     '       'plasticize                      '       \n",
            "'brominate                       '       'demodulate                      '       'repicking                       '       'preprocessed                    '       'hsms285x                        '       \n",
            "'∆rx                             '       'mm/5.5                          '       'self-controlled                 '       'contraindicate                  '       'resect                          '       \n",
            "'lyophilize                      '       'co-localizes                    '       'increased/normalized            '       'pgsup                           '       'dysregulated                    '       \n",
            "'desalt                          '       'overexpress                     '       'engraft                         '       'downregulating                  '       'waitlisted                      '       \n",
            "'dysregulated                    '       'dysregulated                    '       'fractionate                     '       'mm-sized                        '       'macrodissected                  '       \n",
            "'≥15                             '       'repolished                      '       'force/cutting                   '       'rescale                         '       'enchain                         '       \n",
            "'°                               '       'co-working                      '       'passivated                      '       'ca-sa                           '       'calcine                         '       \n",
            "'upregulating                    '       'hydrogenate                     '       'co-processing                   '       'downregulating                  '       'lithiated                       '       \n",
            "'carbonylated                    '       'mineralize                      '       'lepidissimum                    '       'pre-treated                     '       'down-regulating                 '       \n",
            "'equivalized                     '       'hospitalise                     '       'standing/walking                '       '（                               '       'extubated                       '       \n",
            "'vitrify                         '       'resynchronize                   '       'overdispersed                   '       '×                               '       '´                               '       \n",
            "'re-infected                     '       'phagocytosed                    '       'immunolabelled                  '       '≥15                             '       '≤1                              '       \n",
            "'woodsmoke                       '       'dichotomise                     '       '®                               '       'clinical/navigation             '       'upregulating                    '       \n",
            "'serotyped                       '       'catheterise                     '       '×                               '       'co-formulated                   '       'dysregulated                    '       \n",
            "'dysregulated                    '       'adjuvanted                      '       'sublining                       '       'meta-analyzed                   '       'resect                          '       \n",
            "'dichotomize                     '       'triaging                        '       '≥15                             '       'postloading                     '       'thiolated                       '       \n",
            "'trans-differentiation           '       'co-cultured                     '       'co-isolated                     '       '±5                              '       'conceptualise                   '       \n",
            "'conceptualise                   '       'demineralize                    '       'sgus                            '       'downregulating                  '       'randomise                       '       \n",
            "'≥20                             '       'bnt-162b2                       '       'groc                            '       'integerated                     '       'misallocating                   '       \n",
            "'downregulating                  '       'titrate                         '       'video-record                    '       'oe-                             '       'rebleeding                      '       \n",
            "'contitutes                      '       'inhls                           '       'tomography/computed             '       'phagocytose                     '       'pre-sensitized                  '       \n",
            "'incise                          '       \n",
            "\n",
            "Total number of words not in dictionary is 211.\n",
            "********************************************************************************************************************************************************************************************************\n",
            "Finished creating embeddings\n",
            "Valid words count: 34561\n",
            "********************************************************************************************************************************************************************************************************\n",
            "Start clustering\n",
            "Finished clustering\n",
            "Cluster centers count: 297    with threshold of 0.7\n",
            "********************************************************************************************************************************************************************************************************\n",
            "Start inferencing cluster center word\n",
            "Finished inferencing cluster center word\n",
            "********************************************************************************************************************************************************************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c2 = Clustering(word2vec_model)\n",
        "word2vec_result_re = c2.get_cluster_word(df_re, 0.7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ufxRMrQw8q5",
        "outputId": "a6d05506-ca69-4741-b62a-59e67532e10f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************************************************************************************************************************************************************************************************\n",
            "Total input length: 34772\n",
            "********************************************************************************************************************************************************************************************************\n",
            "Finished lemmatizing, checking words not in model vocabulary: \n",
            "\n",
            "'west-single-point               '       'dropcasted                      '       'catalyse                        '       'catalyse                        '       'analyse                         '       \n",
            "'extravasate                     '       'practise                        '       'self-scheduled                  '       '´                               '       '´                               '       \n",
            "'analyse                         '       'characterise                    '       'co-deliver                      '       'co-deliver                      '       'recategorising                  '       \n",
            "'≥3.70                           '       'standardise                     '       'cross-link                      '       'characterise                    '       'tphp-polluted                   '       \n",
            "'chemisorb                       '       'co-existed                      '       'prioritise                      '       'gss                             '       'synthetized                     '       \n",
            "'co-occur                        '       're-evaluated                    '       'analyse                         '       'analyse                         '       'optimise                        '       \n",
            "'analyse                         '       'analyse                         '       'acetylate                       '       'doliiform                       '       'reisolated                      '       \n",
            "'co-exist                        '       'analyse                         '       'stimulate/alter                 '       'analyse                         '       'localise                        '       \n",
            "'enrol                           '       'emphasise                       '       'analyse                         '       'co-exist                        '       'recognise                       '       \n",
            "'synchronise                     '       'hypomethylated                  '       'hypomethylated                  '       'hypomethylated                  '       'recognise                       '       \n",
            "'followed-up                     '       'followed-up                     '       'optimise                        '       'normalise                       '       'generalise                      '       \n",
            "'( bdmards ) /targeted           '       'receinving                      '       '( creb ) -regulated             '       'dialternating                   '       'favour                          '       \n",
            "'over-represented                '       'cross-compared                  '       'localise                        '       'revolutionise                   '       'top-performing                  '       \n",
            "'summarise                       '       'enrol                           '       'enrol                           '       'fulfil                          '       'subclassified                   '       \n",
            "'de-correlate                    '       'phenotyped                      '       'dedifferentiate                 '       'co-expressed                    '       'down-regulated                  '       \n",
            "'maf/nr1h3-expressing            '       'proning                         '       'recognise                       '       'recognise                       '       'enrol                           '       \n",
            "'∗                               '       'utilise                         '       'disilaborirenes                 '       'analyse                         '       'utilise                         '       \n",
            "'enrol                           '       'intercalate                     '       'preexist                        '       '99mtc-labeled                   '       'enrol                           '       \n",
            "'enrol                           '       'ubiquitinates                   '       'co-operate                      '       'failure/left                    '       'enrol                           '       \n",
            "'analyse                         '       'co-cultured                     '       'interquartile                   '       'interquartile                   '       'organise                        '       \n",
            "'emphasise                       '       'localise                        '       'enrol                           '       'disbud                          '       'self-evolve                     '       \n",
            "'dpg-based                       '       'down-regulated                  '       'vdw-based                       '       'co-occurring                    '       'analyse                         '       \n",
            "'coexpressed                     '       'co-localize                     '       'generalise                      '       '2.81±2.73                       '       'recognise                       '       \n",
            "'visualise                       '       'recognise                       '       'colonise                        '       'enrol                           '       'dichotomize                     '       \n",
            "'photogenerated                  '       'administration-approved         '       'co-designed                     '       'down-regulated                  '       'prioritise                      '       \n",
            "'optimise                        '       'resynthesize                    '       'realise                         '       'esplénico                       '       'seguida                         '       \n",
            "'demostró                        '       'temprana                        '       'sometidos                       '       'elegibles                       '       'pedicled                        '       \n",
            "'standardise                     '       'car-sharing                     '       'analyse                         '       'analyse                         '       'recognise                       '       \n",
            "'recognise                       '       'harbour                         '       'up-regulated                    '       '( i/r ) -induced                '       'utilise                         '       \n",
            "'≥61                             '       'summarise                       '       'cotesting                       '       'benzoides                       '       'enrol                           '       \n",
            "'recognise                       '       'acetylate                       '       'fulfil                          '       '( hr-qol ) -measured            '       'co-existing                     '       \n",
            "'deacetylated                    '       're-categorizes                  '       'enrol                           '       'favour                          '       'optimise                        '       \n",
            "'optimise                        '       'infra-red                       '       'imidized                        '       'esterify                        '       'nau-nbt                         '       \n",
            "'( f-m ) -were                   '       'utilise                         '       'time-determined                 '       'gisevii                         '       'demethylate                     '       \n",
            "'plasticize                      '       'characterise                    '       'brominate                       '       'characterise                    '       '( ppo ) -based                  '       \n",
            "'repicking                       '       'optimise                        '       'hsms285x                        '       'analyse                         '       'harmonise                       '       \n",
            "'∆rx                             '       'mm/5.5                          '       'self-controlled                 '       'analyse                         '       'lyophilize                      '       \n",
            "'co-localizes                    '       'phosphorylating                 '       'increased/normalized            '       'pgsup                           '       'analyse                         '       \n",
            "'characterise                    '       '( sgag ) -based                 '       'desalt                          '       'analyse                         '       'analyse                         '       \n",
            "'( ip3r ) -mediated              '       'up-regulated                    '       'characterise                    '       'analyse                         '       'fulfil                          '       \n",
            "'enrol                           '       'enrol                           '       'mm-sized                        '       'fda-approved                    '       'macrodissected                  '       \n",
            "'≥15                             '       'high-speed                      '       'analyse                         '       'analyse                         '       'force/cutting                   '       \n",
            "'enchain                         '       'co-working                      '       'analyse                         '       'ca-sa                           '       'realise                         '       \n",
            "'visualise                       '       'hydrolyse                       '       '( lc/ms ) -based                '       'co-processing                   '       'lithiated                       '       \n",
            "'carbonylated                    '       '( rgo ) -supported              '       'plant-derived                   '       'lepidissimum                    '       'fulfil                          '       \n",
            "'pre-treated                     '       'down-regulating                 '       'analyse                         '       'characterise                    '       'analyse                         '       \n",
            "'fulfil                          '       'analyse                         '       'summarise                       '       'optimise                        '       'standing/walking                '       \n",
            "'recognise                       '       'standardise                     '       'optimise                        '       'emphasise                       '       'enrol                           '       \n",
            "'（                               '       'vitrify                         '       'analyse                         '       'analyse                         '       'down-regulated                  '       \n",
            "'analyse                         '       'enrol                           '       'analyse                         '       'overdispersed                   '       'enrol                           '       \n",
            "'characterise                    '       'recognise                       '       're-evaluated                    '       '´                               '       'analyse                         '       \n",
            "'re-infected                     '       'phagocytosed                    '       'immunolabelled                  '       'analyse                         '       '≥15                             '       \n",
            "'utilise                         '       'follow-up                       '       'follow-up                       '       '≤1                              '       'jeopardise                      '       \n",
            "'dichotomise                     '       'analyse                         '       'co-occurring                    '       'enrol                           '       'recognise                       '       \n",
            "'clinical/navigation             '       'enrol                           '       'utilise                         '       'analyse                         '       'serotyped                       '       \n",
            "'catheterise                     '       'characterise                    '       'co-formulated                   '       'analyse                         '       'enrol                           '       \n",
            "'( pm2.5 ) -associated           '       'follow-up                       '       'redescribed                     '       'co-occurring                    '       'down-regulated                  '       \n",
            "'categorise                      '       'sublining                       '       'meta-analyzed                   '       'enrol                           '       'dichotomize                     '       \n",
            "'stigmatise                      '       '≥15                             '       'postloading                     '       'summarise                       '       'analyse                         '       \n",
            "'well-documented                 '       'thiolated                       '       'trans-differentiation           '       'co-cultured                     '       'up-regulated                    '       \n",
            "'co-isolated                     '       '±5                              '       'enrol                           '       'plough                          '       'fulfil                          '       \n",
            "'analyse                         '       'organise                        '       'minimise                        '       'analyse                         '       'characterise                    '       \n",
            "'demineralize                    '       'sgus                            '       '≥20                             '       'bnt-162b2                       '       're-scheduled                    '       \n",
            "'groc                            '       'analyse                         '       'integerated                     '       'fulfil                          '       'characterise                    '       \n",
            "'analyse                         '       'switched-on                     '       'enrol                           '       'video-record                    '       'oe-                             '       \n",
            "'contitutes                      '       'well-documented                 '       're-raised                       '       'colour                          '       'inhls                           '       \n",
            "'tomography/computed             '       'enrol                           '       'phagocytose                     '       'pre-sensitized                  '       'enrol                           '       \n",
            "'characterise                    '       'analyse                         '       'enrol                           '       'harbour                         '       'enrol                           '       \n",
            "\n",
            "\n",
            "Total number of words not in dictionary is 340.\n",
            "********************************************************************************************************************************************************************************************************\n",
            "Finished creating embeddings\n",
            "Valid words count: 34432\n",
            "********************************************************************************************************************************************************************************************************\n",
            "Start clustering\n",
            "Finished clustering\n",
            "Cluster centers count: 542    with threshold of 0.7\n",
            "********************************************************************************************************************************************************************************************************\n",
            "Start inferencing cluster center word\n",
            "Finished inferencing cluster center word\n",
            "********************************************************************************************************************************************************************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save and load result dataframe"
      ],
      "metadata": {
        "id": "LmfDLzHKFmd_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save_pickle(glove_result_re, \"glove_res_10000\")"
      ],
      "metadata": {
        "id": "rRFYWc5WFqOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_pickle(word2vec_result_re, \"word2vec_res_10000\")"
      ],
      "metadata": {
        "id": "ptHD_0ZiE7UL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glove_result_re_load = load_pickle(\"glove_res_10000\")"
      ],
      "metadata": {
        "id": "rnCqwzX3FtuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2vec_result_re_load = load_pickle(\"word2vec_res_10000\")"
      ],
      "metadata": {
        "id": "L2vv5IBqFOMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2vec_result_re_load[word2vec_result_re_load.duplicated(subset = ['entity_1','entity_2'], keep = False)].sort_values(\"entity_1\")[[\"entity_1\", \"entity_2\", \"cluster_word\"]][:50]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Cvs8RS08DUw3",
        "outputId": "ea938693-05f3-43f3-c3e9-2a39adff562c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-46bd5390-58af-4d97-8ab7-0fbe42f8167c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>entity_1</th>\n",
              "      <th>entity_2</th>\n",
              "      <th>cluster_word</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1516</th>\n",
              "      <td>5p</td>\n",
              "      <td>proliferation</td>\n",
              "      <td>modulate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1515</th>\n",
              "      <td>5p</td>\n",
              "      <td>proliferation</td>\n",
              "      <td>modulate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23429</th>\n",
              "      <td>COVID-19</td>\n",
              "      <td>pandemic</td>\n",
              "      <td>appear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8487</th>\n",
              "      <td>COVID-19</td>\n",
              "      <td>pandemic</td>\n",
              "      <td>result</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10071</th>\n",
              "      <td>COVID-19</td>\n",
              "      <td>pandemic</td>\n",
              "      <td>compare</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>865</th>\n",
              "      <td>COVID-19</td>\n",
              "      <td>pandemic</td>\n",
              "      <td>prove</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25936</th>\n",
              "      <td>COVID-19 pandemic</td>\n",
              "      <td>mental health</td>\n",
              "      <td>cause</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24645</th>\n",
              "      <td>COVID-19 pandemic</td>\n",
              "      <td>SARS-CoV-2 virus</td>\n",
              "      <td>cause</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24647</th>\n",
              "      <td>COVID-19 pandemic</td>\n",
              "      <td>SARS-CoV-2 virus</td>\n",
              "      <td>cause</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34494</th>\n",
              "      <td>COVID-19 pandemic</td>\n",
              "      <td>mental health</td>\n",
              "      <td>aid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29974</th>\n",
              "      <td>CT-derived features</td>\n",
              "      <td>bone-free dataset</td>\n",
              "      <td>reduce</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29980</th>\n",
              "      <td>CT-derived features</td>\n",
              "      <td>bone-free dataset</td>\n",
              "      <td>reduce</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28089</th>\n",
              "      <td>Coronavirus disease</td>\n",
              "      <td>severe acute respiratory syndrome</td>\n",
              "      <td>produce</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4879</th>\n",
              "      <td>Coronavirus disease</td>\n",
              "      <td>severe acute respiratory syndrome</td>\n",
              "      <td>cause</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1522</th>\n",
              "      <td>GPX4</td>\n",
              "      <td>shMTHFD2</td>\n",
              "      <td>induce</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1527</th>\n",
              "      <td>GPX4</td>\n",
              "      <td>shMTHFD2</td>\n",
              "      <td>induce</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21965</th>\n",
              "      <td>Gd2O3</td>\n",
              "      <td>thermal conductivity</td>\n",
              "      <td>dope</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21968</th>\n",
              "      <td>Gd2O3</td>\n",
              "      <td>thermal conductivity</td>\n",
              "      <td>reduce</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13033</th>\n",
              "      <td>H2</td>\n",
              "      <td>self-healing process</td>\n",
              "      <td>facilitate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13030</th>\n",
              "      <td>H2</td>\n",
              "      <td>self-healing process</td>\n",
              "      <td>facilitate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30657</th>\n",
              "      <td>Hosmer-Lemeshow test</td>\n",
              "      <td>logistic regression model</td>\n",
              "      <td>demonstrate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30653</th>\n",
              "      <td>Hosmer-Lemeshow test</td>\n",
              "      <td>logistic regression model</td>\n",
              "      <td>perform</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31439</th>\n",
              "      <td>IGF2BP1</td>\n",
              "      <td>cisplatin resistance in oral squamous cell car...</td>\n",
              "      <td>associate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31438</th>\n",
              "      <td>IGF2BP1</td>\n",
              "      <td>cisplatin resistance in oral squamous cell car...</td>\n",
              "      <td>improve</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13775</th>\n",
              "      <td>IR</td>\n",
              "      <td>white light</td>\n",
              "      <td>discriminate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13773</th>\n",
              "      <td>IR</td>\n",
              "      <td>white light</td>\n",
              "      <td>identify</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5869</th>\n",
              "      <td>Indocyanine green</td>\n",
              "      <td>test compound</td>\n",
              "      <td>apply</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5893</th>\n",
              "      <td>Indocyanine green</td>\n",
              "      <td>test compound</td>\n",
              "      <td>apply</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33159</th>\n",
              "      <td>Irritability</td>\n",
              "      <td>patients with hydrocephalus</td>\n",
              "      <td>occur</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33158</th>\n",
              "      <td>Irritability</td>\n",
              "      <td>patients with hydrocephalus</td>\n",
              "      <td>occur</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8162</th>\n",
              "      <td>Kir3.2 G156S</td>\n",
              "      <td>cations</td>\n",
              "      <td>require</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8167</th>\n",
              "      <td>Kir3.2 G156S</td>\n",
              "      <td>cations</td>\n",
              "      <td>require</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31247</th>\n",
              "      <td>MARS-Net</td>\n",
              "      <td>transfer learning and data</td>\n",
              "      <td>use</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31245</th>\n",
              "      <td>MARS-Net</td>\n",
              "      <td>transfer learning and data</td>\n",
              "      <td>use</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30658</th>\n",
              "      <td>Male gender</td>\n",
              "      <td>cardiac surgery</td>\n",
              "      <td>follow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30656</th>\n",
              "      <td>Male gender</td>\n",
              "      <td>cardiac surgery</td>\n",
              "      <td>identify</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6813</th>\n",
              "      <td>PCR methods</td>\n",
              "      <td>EGFR mutations</td>\n",
              "      <td>detect</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6812</th>\n",
              "      <td>PCR methods</td>\n",
              "      <td>EGFR mutations</td>\n",
              "      <td>use</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>289</th>\n",
              "      <td>RNA</td>\n",
              "      <td>Pol</td>\n",
              "      <td>cap</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284</th>\n",
              "      <td>RNA</td>\n",
              "      <td>Pol</td>\n",
              "      <td>cap</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34456</th>\n",
              "      <td>Rehabilitation professionals</td>\n",
              "      <td>frailty</td>\n",
              "      <td>consider</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34457</th>\n",
              "      <td>Rehabilitation professionals</td>\n",
              "      <td>frailty</td>\n",
              "      <td>consider</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20130</th>\n",
              "      <td>SEMA6D</td>\n",
              "      <td>microRNAs</td>\n",
              "      <td>associate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20129</th>\n",
              "      <td>SEMA6D</td>\n",
              "      <td>microRNAs</td>\n",
              "      <td>define</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34753</th>\n",
              "      <td>Statistical analysis</td>\n",
              "      <td>SPSS</td>\n",
              "      <td>perform</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31442</th>\n",
              "      <td>Statistical analysis</td>\n",
              "      <td>software package</td>\n",
              "      <td>perform</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31449</th>\n",
              "      <td>Statistical analysis</td>\n",
              "      <td>SPSS</td>\n",
              "      <td>process</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31459</th>\n",
              "      <td>Statistical analysis</td>\n",
              "      <td>SPSS</td>\n",
              "      <td>perform</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31494</th>\n",
              "      <td>Statistical analysis</td>\n",
              "      <td>software package</td>\n",
              "      <td>perform</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33110</th>\n",
              "      <td>acupuncture</td>\n",
              "      <td>endometriosis</td>\n",
              "      <td>treat</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-46bd5390-58af-4d97-8ab7-0fbe42f8167c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-46bd5390-58af-4d97-8ab7-0fbe42f8167c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-46bd5390-58af-4d97-8ab7-0fbe42f8167c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                           entity_1  ...  cluster_word\n",
              "1516                             5p  ...      modulate\n",
              "1515                             5p  ...      modulate\n",
              "23429                      COVID-19  ...        appear\n",
              "8487                       COVID-19  ...        result\n",
              "10071                      COVID-19  ...       compare\n",
              "865                        COVID-19  ...         prove\n",
              "25936             COVID-19 pandemic  ...         cause\n",
              "24645             COVID-19 pandemic  ...         cause\n",
              "24647             COVID-19 pandemic  ...         cause\n",
              "34494             COVID-19 pandemic  ...           aid\n",
              "29974           CT-derived features  ...        reduce\n",
              "29980           CT-derived features  ...        reduce\n",
              "28089           Coronavirus disease  ...       produce\n",
              "4879            Coronavirus disease  ...         cause\n",
              "1522                           GPX4  ...        induce\n",
              "1527                           GPX4  ...        induce\n",
              "21965                         Gd2O3  ...          dope\n",
              "21968                         Gd2O3  ...        reduce\n",
              "13033                            H2  ...    facilitate\n",
              "13030                            H2  ...    facilitate\n",
              "30657          Hosmer-Lemeshow test  ...   demonstrate\n",
              "30653          Hosmer-Lemeshow test  ...       perform\n",
              "31439                       IGF2BP1  ...     associate\n",
              "31438                       IGF2BP1  ...       improve\n",
              "13775                            IR  ...  discriminate\n",
              "13773                            IR  ...      identify\n",
              "5869              Indocyanine green  ...         apply\n",
              "5893              Indocyanine green  ...         apply\n",
              "33159                  Irritability  ...         occur\n",
              "33158                  Irritability  ...         occur\n",
              "8162                   Kir3.2 G156S  ...       require\n",
              "8167                   Kir3.2 G156S  ...       require\n",
              "31247                      MARS-Net  ...           use\n",
              "31245                      MARS-Net  ...           use\n",
              "30658                   Male gender  ...        follow\n",
              "30656                   Male gender  ...      identify\n",
              "6813                    PCR methods  ...        detect\n",
              "6812                    PCR methods  ...           use\n",
              "289                             RNA  ...           cap\n",
              "284                             RNA  ...           cap\n",
              "34456  Rehabilitation professionals  ...      consider\n",
              "34457  Rehabilitation professionals  ...      consider\n",
              "20130                        SEMA6D  ...     associate\n",
              "20129                        SEMA6D  ...        define\n",
              "34753          Statistical analysis  ...       perform\n",
              "31442          Statistical analysis  ...       perform\n",
              "31449          Statistical analysis  ...       process\n",
              "31459          Statistical analysis  ...       perform\n",
              "31494          Statistical analysis  ...       perform\n",
              "33110                   acupuncture  ...         treat\n",
              "\n",
              "[50 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare performance"
      ],
      "metadata": {
        "id": "hEw8M8MBHgU0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "comparison = glove_result_re_load[[\"entity_1\", \"entity_2\", \"relationship\", \"cluster_word\"]].rename(columns = {\"cluster_word\" : \"glove_cluster_word\"})"
      ],
      "metadata": {
        "id": "ZVgvqpiQG8Ej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comparison[\"word2vec_cluster_word\"] = word2vec_result_re_load[\"cluster_word\"]"
      ],
      "metadata": {
        "id": "fNAVkL0bGcrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comparison[:50]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AZIPLJuCGoMd",
        "outputId": "70c4e673-0111-46c0-cfee-8eab4a6f32d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-31f1bbe2-ee28-48a1-bd0c-fc6057417a01\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>entity_1</th>\n",
              "      <th>entity_2</th>\n",
              "      <th>relationship</th>\n",
              "      <th>glove_cluster_word</th>\n",
              "      <th>word2vec_cluster_word</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Severe COVID-19</td>\n",
              "      <td>venous thromboembolic events</td>\n",
              "      <td>associated</td>\n",
              "      <td>associate</td>\n",
              "      <td>associate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>hospital stays</td>\n",
              "      <td>limb arthroplasty</td>\n",
              "      <td>implies</td>\n",
              "      <td>correspond</td>\n",
              "      <td>indicate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>postoperative process</td>\n",
              "      <td>safety and patient satisfaction</td>\n",
              "      <td>limit</td>\n",
              "      <td>reduce</td>\n",
              "      <td>limit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>patient-centred information and education</td>\n",
              "      <td>complicated postoperative outcomes</td>\n",
              "      <td>recommended</td>\n",
              "      <td>examine</td>\n",
              "      <td>propose</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>delay in treatment</td>\n",
              "      <td>treatment with guideline-recommended angiotens...</td>\n",
              "      <td>fail</td>\n",
              "      <td>consider</td>\n",
              "      <td>fail</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Retrospective analysis</td>\n",
              "      <td>administrative claims database</td>\n",
              "      <td>using</td>\n",
              "      <td>use</td>\n",
              "      <td>use</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>cohort</td>\n",
              "      <td>laboratory test</td>\n",
              "      <td>met</td>\n",
              "      <td>receive</td>\n",
              "      <td>meet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>albuminuria</td>\n",
              "      <td>sodium-glucose cotransporter</td>\n",
              "      <td>used</td>\n",
              "      <td>use</td>\n",
              "      <td>use</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>complications</td>\n",
              "      <td>medical costs</td>\n",
              "      <td>estimated</td>\n",
              "      <td>estimate</td>\n",
              "      <td>estimate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Mortality costs</td>\n",
              "      <td>month before death</td>\n",
              "      <td>assessed</td>\n",
              "      <td>examine</td>\n",
              "      <td>compare</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Nanocrystal surfaces</td>\n",
              "      <td>organic ligands</td>\n",
              "      <td>populated</td>\n",
              "      <td>reside</td>\n",
              "      <td>occupy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>QENS spectra</td>\n",
              "      <td>time-of-flight spectrometer</td>\n",
              "      <td>collected</td>\n",
              "      <td>use</td>\n",
              "      <td>collect</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>molecular axis</td>\n",
              "      <td>uniaxial rotation</td>\n",
              "      <td>undergo</td>\n",
              "      <td>perform</td>\n",
              "      <td>undergo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>ligands</td>\n",
              "      <td>average relaxation</td>\n",
              "      <td>undergoing</td>\n",
              "      <td>perform</td>\n",
              "      <td>undergo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>neighboring nanocrystals</td>\n",
              "      <td>uniaxial rotation and that longer ligands</td>\n",
              "      <td>exhibit</td>\n",
              "      <td>exhibit</td>\n",
              "      <td>show</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>ligands in nanocrystal solids</td>\n",
              "      <td>mechanical and thermal properties</td>\n",
              "      <td>understanding</td>\n",
              "      <td>understand</td>\n",
              "      <td>explain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>gram-negative pathogen</td>\n",
              "      <td>siderophores</td>\n",
              "      <td>secretes</td>\n",
              "      <td>degrade</td>\n",
              "      <td>oxidize</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>heme</td>\n",
              "      <td>uptake pathways</td>\n",
              "      <td>uses</td>\n",
              "      <td>use</td>\n",
              "      <td>use</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>pathways in iron-restricted growth conditions</td>\n",
              "      <td>proteomic and RT-qPCR approaches</td>\n",
              "      <td>using</td>\n",
              "      <td>use</td>\n",
              "      <td>use</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>hemin</td>\n",
              "      <td>siderophores</td>\n",
              "      <td>result</td>\n",
              "      <td>result</td>\n",
              "      <td>result</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>pathogen</td>\n",
              "      <td>phenotype</td>\n",
              "      <td>adapts</td>\n",
              "      <td>integrate</td>\n",
              "      <td>adjust</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>xenosiderophore</td>\n",
              "      <td>Hxu systems</td>\n",
              "      <td>resulted</td>\n",
              "      <td>result</td>\n",
              "      <td>result</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>metal pincer complexes</td>\n",
              "      <td>pincer ligands</td>\n",
              "      <td>supported</td>\n",
              "      <td>receive</td>\n",
              "      <td>support</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Theoretical calculations</td>\n",
              "      <td>relative bond strength</td>\n",
              "      <td>selected</td>\n",
              "      <td>select</td>\n",
              "      <td>select</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Photodynamic therapy</td>\n",
              "      <td>tumor therapy</td>\n",
              "      <td>used</td>\n",
              "      <td>use</td>\n",
              "      <td>use</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>clinical application</td>\n",
              "      <td>weak efficacy</td>\n",
              "      <td>limited</td>\n",
              "      <td>reduce</td>\n",
              "      <td>limit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>theranostic nanoplatform</td>\n",
              "      <td>tumor cells</td>\n",
              "      <td>kill</td>\n",
              "      <td>kill</td>\n",
              "      <td>die</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>light harvesting</td>\n",
              "      <td>photocatalytic CO2 reduction</td>\n",
              "      <td>proven</td>\n",
              "      <td>prove</td>\n",
              "      <td>prove</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>biotemplating approach</td>\n",
              "      <td>hierarchical structures</td>\n",
              "      <td>employed</td>\n",
              "      <td>involve</td>\n",
              "      <td>use</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>finite-difference time-domain method</td>\n",
              "      <td>unique periodic hierarchical structure</td>\n",
              "      <td>suggest</td>\n",
              "      <td>result</td>\n",
              "      <td>indicate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>photocatalysts</td>\n",
              "      <td>biological structures</td>\n",
              "      <td>based</td>\n",
              "      <td>base</td>\n",
              "      <td>base</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>applications in fields</td>\n",
              "      <td>sensors to biomedical imaging</td>\n",
              "      <td>ranging</td>\n",
              "      <td>range</td>\n",
              "      <td>target</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>building blocks</td>\n",
              "      <td>individual coronae</td>\n",
              "      <td>form</td>\n",
              "      <td>present</td>\n",
              "      <td>form</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>hydrophilic polyethylene glycol</td>\n",
              "      <td>structural freedom</td>\n",
              "      <td>synthesized</td>\n",
              "      <td>analyze</td>\n",
              "      <td>integrate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>dendrons</td>\n",
              "      <td>amphiphiles</td>\n",
              "      <td>show</td>\n",
              "      <td>show</td>\n",
              "      <td>show</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>biological functions</td>\n",
              "      <td>myocardial protection</td>\n",
              "      <td>including</td>\n",
              "      <td>include</td>\n",
              "      <td>include</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>pathological scores</td>\n",
              "      <td>tissue integrity</td>\n",
              "      <td>preserved</td>\n",
              "      <td>preserve</td>\n",
              "      <td>protect</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>E3 ubiquitin ligase</td>\n",
              "      <td>ubiquitination</td>\n",
              "      <td>promoted</td>\n",
              "      <td>improve</td>\n",
              "      <td>improve</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Treg differentiation</td>\n",
              "      <td>Th17 cell development during colitis</td>\n",
              "      <td>suppressing</td>\n",
              "      <td>suppress</td>\n",
              "      <td>suppress</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>Th17/Treg axis</td>\n",
              "      <td>protection against experimental colitis</td>\n",
              "      <td>confers</td>\n",
              "      <td>recognize</td>\n",
              "      <td>confer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>aqueous rechargeable zinc-ion battery</td>\n",
              "      <td>open framework</td>\n",
              "      <td>owing</td>\n",
              "      <td>owe</td>\n",
              "      <td>owe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Zn anode and the CuHCF cathode</td>\n",
              "      <td>aging during cycling</td>\n",
              "      <td>show</td>\n",
              "      <td>show</td>\n",
              "      <td>show</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>cathode</td>\n",
              "      <td>X-ray spectroscopic techniques</td>\n",
              "      <td>employing</td>\n",
              "      <td>involve</td>\n",
              "      <td>use</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>structure-related aging effects</td>\n",
              "      <td>compensation processes</td>\n",
              "      <td>charge</td>\n",
              "      <td>charge</td>\n",
              "      <td>charge</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>X-ray diffraction</td>\n",
              "      <td>cycling</td>\n",
              "      <td>appearing</td>\n",
              "      <td>come</td>\n",
              "      <td>appear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>hypothetical ZnCu1-HCF phases</td>\n",
              "      <td>ZnSO4 into graphitic carbon</td>\n",
              "      <td>caused</td>\n",
              "      <td>cause</td>\n",
              "      <td>cause</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>charge/discharge plateaus</td>\n",
              "      <td>cycling</td>\n",
              "      <td>repeated</td>\n",
              "      <td>correct</td>\n",
              "      <td>repeat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>SO42- anions</td>\n",
              "      <td>CuHCF during charge</td>\n",
              "      <td>insert</td>\n",
              "      <td>activate</td>\n",
              "      <td>attach</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>cathode and pinpoints parameters</td>\n",
              "      <td>Prussian blue analogue-type cathodes</td>\n",
              "      <td>correlate</td>\n",
              "      <td>correlate</td>\n",
              "      <td>correlate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>Histone methylations</td>\n",
              "      <td>chromatin remodeling and genome regulations</td>\n",
              "      <td>play</td>\n",
              "      <td>lead</td>\n",
              "      <td>play</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-31f1bbe2-ee28-48a1-bd0c-fc6057417a01')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-31f1bbe2-ee28-48a1-bd0c-fc6057417a01 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-31f1bbe2-ee28-48a1-bd0c-fc6057417a01');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                         entity_1  ... word2vec_cluster_word\n",
              "0                                 Severe COVID-19  ...             associate\n",
              "1                                  hospital stays  ...              indicate\n",
              "2                           postoperative process  ...                 limit\n",
              "3       patient-centred information and education  ...               propose\n",
              "4                              delay in treatment  ...                  fail\n",
              "5                          Retrospective analysis  ...                   use\n",
              "6                                          cohort  ...                  meet\n",
              "7                                     albuminuria  ...                   use\n",
              "8                                   complications  ...              estimate\n",
              "9                                 Mortality costs  ...               compare\n",
              "10                           Nanocrystal surfaces  ...                occupy\n",
              "11                                   QENS spectra  ...               collect\n",
              "12                                 molecular axis  ...               undergo\n",
              "13                                        ligands  ...               undergo\n",
              "14                       neighboring nanocrystals  ...                  show\n",
              "15                  ligands in nanocrystal solids  ...               explain\n",
              "16                         gram-negative pathogen  ...               oxidize\n",
              "17                                           heme  ...                   use\n",
              "18  pathways in iron-restricted growth conditions  ...                   use\n",
              "19                                          hemin  ...                result\n",
              "20                                       pathogen  ...                adjust\n",
              "21                                xenosiderophore  ...                result\n",
              "22                         metal pincer complexes  ...               support\n",
              "23                       Theoretical calculations  ...                select\n",
              "24                           Photodynamic therapy  ...                   use\n",
              "25                           clinical application  ...                 limit\n",
              "26                       theranostic nanoplatform  ...                   die\n",
              "27                               light harvesting  ...                 prove\n",
              "28                         biotemplating approach  ...                   use\n",
              "29           finite-difference time-domain method  ...              indicate\n",
              "30                                 photocatalysts  ...                  base\n",
              "31                         applications in fields  ...                target\n",
              "32                                building blocks  ...                  form\n",
              "33                hydrophilic polyethylene glycol  ...             integrate\n",
              "34                                       dendrons  ...                  show\n",
              "35                           biological functions  ...               include\n",
              "36                            pathological scores  ...               protect\n",
              "37                            E3 ubiquitin ligase  ...               improve\n",
              "38                           Treg differentiation  ...              suppress\n",
              "39                                 Th17/Treg axis  ...                confer\n",
              "40          aqueous rechargeable zinc-ion battery  ...                   owe\n",
              "41                 Zn anode and the CuHCF cathode  ...                  show\n",
              "42                                        cathode  ...                   use\n",
              "43                structure-related aging effects  ...                charge\n",
              "44                              X-ray diffraction  ...                appear\n",
              "45                  hypothetical ZnCu1-HCF phases  ...                 cause\n",
              "46                      charge/discharge plateaus  ...                repeat\n",
              "47                                   SO42- anions  ...                attach\n",
              "48               cathode and pinpoints parameters  ...             correlate\n",
              "49                           Histone methylations  ...                  play\n",
              "\n",
              "[50 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zKNMhmDe8aaw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9wTeJ-kF8adQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GPT3**"
      ],
      "metadata": {
        "id": "EcCfogRw8af1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "# Load your API key from an environment variable or secret management service\n",
        "openai.api_key = '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'\n",
        "\n",
        "prompt = \"\"\"We want to recognize entities in a sentence.\n",
        "       For example, in sentence 'Severe COVID-19 is associated with venous thromboembolic events and immuno-thrombotic phenomena, \n",
        "       responsible for pulmonary vascular damage.', the entities that should be identified are 'Sever COVID-19' and 'venous thromboembolic events'.\n",
        "       \n",
        "       Another example is, in the sentence 'Photodynamic therapy (PDT) has been widely used in tumor therapy due to its high \n",
        "       spatial-temporal control and noninvasiveness.', the entities that should be identified are 'Photodynamic therapy' and 'tumor therapy'.\n",
        "       \n",
        "       Now please extract entities on the following sentences: 'This review summarizes the current knowledge on thrombotic risk \n",
        "       in COVID-19 inpatients, the potential predictive factors (including D-dimer) and the randomized trials studying the \n",
        "       effect of intermediate or therapeutic-dose anticoagulation on the clinical and thrombotic prognosis.'\n",
        "     \"\"\"\n",
        "      \n",
        "response = openai.Completion.create(model=\"text-davinci-002\", prompt=prompt, temperature=0, max_tokens=60)\n",
        "response[\"choices\"]"
      ],
      "metadata": {
        "id": "YpDd7Cor8ezI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec5cfd9d-1a24-40ca-80eb-7b0b5a722437"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-11-03 14:58:00,338 - openai - INFO - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions\n",
            "2022-11-03 14:58:02,244 - openai - INFO - message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=1833 request_id=394c145936f2632c08c3777451944957 response_code=200\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<OpenAIObject at 0x7f6cb83bdf50> JSON: {\n",
              "  \"finish_reason\": \"stop\",\n",
              "  \"index\": 0,\n",
              "  \"logprobs\": null,\n",
              "  \"text\": \"\\n       The entities that should be identified are 'thrombotic risk', 'COVID-19 inpatients', 'D-dimer', 'intermediate or therapeutic-dose anticoagulation', and 'clinical and thrombotic prognosis'.\"\n",
              "}]"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing entity extractors"
      ],
      "metadata": {
        "id": "RyExC5bUrU8e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "\n",
        "class EntityExtractor:\n",
        "    def __init__(self, nlp, opennre_model, simple_dict, inflect_converter):\n",
        "        self.nlp = nlp\n",
        "        self.opennre_model = opennre_model\n",
        "        self.simple_dict = simple_dict\n",
        "        self.inflect_converter = inflect_converter\n",
        "\n",
        "    def entity_extraction(self, text_input):\n",
        "        doc = self.nlp(text_input)\n",
        "        ignore_list = []\n",
        "        text_entity_list = []\n",
        "        for sentence in doc.sents:\n",
        "            sentence_entity_list = []\n",
        "            entity_start = -1\n",
        "            entity_end = -1\n",
        "            and_keyword_connecting = False\n",
        "            prev_adp = False\n",
        "            parenthesis_count = 0\n",
        "\n",
        "            for token in sentence:\n",
        "                if token.ent_type != 0 and token.tag_ == 'JJ':\n",
        "                    if entity_start == -1:  # Entering a new entity\n",
        "                        entity_start = token.idx\n",
        "                elif token.ent_type != 0 and token.pos_ == 'NOUN':\n",
        "                    if entity_start == -1:  # Entering a new entity\n",
        "                        entity_start = token.idx\n",
        "                    entity_end = token.idx + len(token)  # Possible to end an entity here\n",
        "                elif token.ent_type != 0 and not prev_adp:\n",
        "                    entity_start = -1\n",
        "                    entity_end = -1\n",
        "                    prev_adp = False\n",
        "                elif token.text == \"of\":  # ignore the previous entity\n",
        "                    entity_start = -1\n",
        "                    entity_end = -1\n",
        "                elif token.pos_ == 'ADP':  # only take entities after proposition\n",
        "                    prev_adp = True\n",
        "                elif token.text == \"and\" and entity_end == -1:  # if not yet reaches the end of an entity\n",
        "                    continue\n",
        "                else:\n",
        "                    # checks if an entity has been formed\n",
        "                    if entity_start != -1 and entity_end != -1:\n",
        "                        if and_keyword_connecting and sentence_entity_list and (\n",
        "                                entity_end - sentence_entity_list[-1]['end'] <= 30):\n",
        "                            # if close enough with previous entity and connected by \"AND\"\n",
        "                            sentence_entity_list[-1]['end'] = entity_end\n",
        "                        else:\n",
        "                            # if is an independent entity and not inside a parenthesis\n",
        "                            if parenthesis_count == 0:\n",
        "                                sentence_entity_list.append(\n",
        "                                    {\"start\": entity_start, \"end\": entity_end, \"label\": \"Entity\"})\n",
        "                            else:\n",
        "                                ignore_list.append(doc.text[entity_start:entity_end])\n",
        "                        and_keyword_connecting = False\n",
        "\n",
        "                    elif token.pos_ == \"NOUN\" and and_keyword_connecting:\n",
        "                        # if is a noun (but not recognized as an entity) and should be connected by AND keyword\n",
        "                        if sentence_entity_list and (token.idx + len(token) - sentence_entity_list[-1]['end'] <= 30):\n",
        "                            sentence_entity_list[-1]['end'] = token.idx + len(token)\n",
        "                        and_keyword_connecting = False\n",
        "\n",
        "                    if token.text == 'and':\n",
        "                        and_keyword_connecting = True\n",
        "\n",
        "                    entity_start = -1\n",
        "                    entity_end = -1\n",
        "\n",
        "                # If we enter a parenthesis, all independent entities inside it should not be considered\n",
        "                if token.text == \"(\":\n",
        "                    parenthesis_count = parenthesis_count + 1\n",
        "                elif token.text == \")\":\n",
        "                    parenthesis_count = parenthesis_count - 1\n",
        "\n",
        "            for ent in sentence_entity_list:\n",
        "                start_index = ent['start']\n",
        "                end_index = ent['end']\n",
        "                entity_text = doc.text[start_index:end_index]\n",
        "                lower_text = entity_text.lower()\n",
        "\n",
        "                # Only consider it to be an entity if it is not a simple word and has not occured within a parethesis\n",
        "                should_add = True\n",
        "                if lower_text in self.simple_dict or self.inflect_converter.singular_noun(\n",
        "                        lower_text) in self.simple_dict:\n",
        "                    should_add = False\n",
        "\n",
        "                for ignore_word in ignore_list:\n",
        "                    if ignore_word in entity_text:\n",
        "                        should_add = False\n",
        "\n",
        "                if should_add:\n",
        "                    text_entity_list.append(ent)\n",
        "\n",
        "        ex = {\n",
        "            \"text\": doc.text,\n",
        "            \"ents\": text_entity_list,\n",
        "            \"title\": None\n",
        "        }\n",
        "\n",
        "        return ex\n",
        "\n",
        "    def get_entity_pairs(self, ex):\n",
        "        doc = self.nlp(ex['text'])\n",
        "        period_idx_list = []\n",
        "        # find the indices of the periods\n",
        "        for token in doc:\n",
        "            if token.text == \".\":\n",
        "                period_idx_list.append(token.idx)\n",
        "\n",
        "        original_text = ex['text']\n",
        "        entities = ex['ents']\n",
        "        entity_pairs_with_confidence = []\n",
        "        curr_sentence_entity_pairs = []\n",
        "\n",
        "        for entity_index in range(0, len(entities) - 1):\n",
        "            # Go over every ADJACENT entity pairs\n",
        "            first_entity = entities[entity_index]\n",
        "            second_entity = entities[entity_index + 1]\n",
        "            if first_entity['start'] == second_entity['start']:\n",
        "                continue\n",
        "\n",
        "            period_in_between = 0\n",
        "            for p in period_idx_list:\n",
        "                if first_entity['start'] < p < second_entity['start']:\n",
        "                    period_in_between += 1\n",
        "\n",
        "            # Only consider entity pairs within the SAME sentence\n",
        "            # If we reach a different sentence, compare all entity pairs in the previous sentence and get the most confident pair\n",
        "            if period_in_between > 0:\n",
        "                if len(curr_sentence_entity_pairs) > 0:\n",
        "                    curr_sentence_entity_pairs.sort(key=lambda x: x[3], reverse=True)  # Sort by confidence level\n",
        "                    entity_pairs_with_confidence.append(\n",
        "                        curr_sentence_entity_pairs[0])  # Only the most confident pair will remain\n",
        "                    curr_sentence_entity_pairs = []\n",
        "                continue\n",
        "\n",
        "            # Find Previous Period and Next Period and use them to cut out sentence containing the two entities\n",
        "            previous_period_order = 0  # Among all those periods, which one is right before the first entity\n",
        "            while previous_period_order < len(period_idx_list) and period_idx_list[previous_period_order] < \\\n",
        "                    first_entity[\n",
        "                        'start']:\n",
        "                previous_period_order = previous_period_order + 1\n",
        "            previous_period_order = previous_period_order - 1\n",
        "\n",
        "            next_period_order = 0  # Among all those periods, which one is right after the second entity\n",
        "            while next_period_order < len(period_idx_list) and period_idx_list[next_period_order] < second_entity[\n",
        "                'end']:\n",
        "                next_period_order = next_period_order + 1\n",
        "\n",
        "            previous_period_pos = period_idx_list[previous_period_order]\n",
        "            if previous_period_order == -1:\n",
        "                previous_period_pos = -1\n",
        "\n",
        "            if next_period_order == len(period_idx_list):\n",
        "                next_period_pos = len(original_text) - 1\n",
        "            else:\n",
        "                next_period_pos = period_idx_list[next_period_order]\n",
        "\n",
        "            relevant_sentence = original_text[previous_period_pos + 1: next_period_pos + 1]\n",
        "            if relevant_sentence[0] == ' ':\n",
        "                relevant_sentence = relevant_sentence[1:]\n",
        "            # The indexes of the two entities in the cut out sentence\n",
        "            first_entity_text = original_text[first_entity['start']:first_entity['end']]\n",
        "            first_entity_start = relevant_sentence.index(first_entity_text)\n",
        "            first_entity_end = first_entity_start + (first_entity['end'] - first_entity['start'])\n",
        "\n",
        "            second_entity_text = original_text[second_entity['start']:second_entity['end']]\n",
        "            second_entity_start = relevant_sentence.index(second_entity_text)\n",
        "            second_entity_end = second_entity_start + (second_entity['end'] - second_entity['start'])\n",
        "\n",
        "            # inferred relation format: ('father', 0.7654321)\n",
        "            inferred_relation = self.opennre_model.infer({'text': relevant_sentence,\n",
        "                                                          'h': {'pos': (first_entity_start, first_entity_end)},\n",
        "                                                          't': {'pos': (second_entity_start, second_entity_end)}})\n",
        "\n",
        "            confidence_level = inferred_relation[1]\n",
        "\n",
        "            relevant_text_between = relevant_sentence[first_entity_end:second_entity_start]\n",
        "\n",
        "            curr_sentence_entity_pairs.append((relevant_sentence, relevant_text_between,\n",
        "                                               relevant_sentence[first_entity_start:first_entity_end],\n",
        "                                               relevant_sentence[second_entity_start:second_entity_end],\n",
        "                                               confidence_level))\n",
        "\n",
        "        if len(curr_sentence_entity_pairs) > 0:\n",
        "            curr_sentence_entity_pairs.sort(key=lambda x: x[4], reverse=True)  # Sort by confidence level\n",
        "            entity_pairs_with_confidence.append(\n",
        "                curr_sentence_entity_pairs[0])  # Only the most confident pair will remain\n",
        "            curr_sentence_entity_pairs = []\n",
        "\n",
        "        entity_pairs = []\n",
        "        for entity_pair in entity_pairs_with_confidence:\n",
        "            entity_pairs.append(\n",
        "                {'sentence': entity_pair[0], 'text_between': entity_pair[1], 'first_entity': entity_pair[2],\n",
        "                 'second_entity': entity_pair[3]})\n",
        "        return entity_pairs\n",
        "\n",
        "    def extract_entities(self, abstracts):\n",
        "        entities_all_docs = []\n",
        "        for i in range(len(abstracts)):\n",
        "            input_text = abstracts[i]\n",
        "            ex = self.entity_extraction(input_text)\n",
        "            entity_pairs = self.get_entity_pairs(ex)\n",
        "            entities_all_docs.append(entity_pairs)\n",
        "        return entities_all_docs\n",
        "        # if not os.path.exists(\"temp\"):\n",
        "        #     os.mkdir(\"temp/\")\n",
        "        # with open(\"temp/entities.json\", 'w') as f:\n",
        "        #     json.dump(entities_all_docs, f)"
      ],
      "metadata": {
        "id": "_YqXZRc4raQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing Implementation"
      ],
      "metadata": {
        "id": "Q0LarZQA9IwR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pymongo\n",
        "with open('/content/connection_mongodb.txt') as f:\n",
        "  mongodb_link = f.readline()\n",
        "\n",
        "client = pymongo.MongoClient(mongodb_link)\n",
        "# Database Name\n",
        "db = client['pubmed']\n",
        "# Collection Name\n",
        "col = db['abstracts']\n",
        "\n",
        "abstracts = col.find({},{'_id':0, 'text':1})\n",
        "abstracts = [a['text'] for a in abstracts]"
      ],
      "metadata": {
        "id": "7FZkODM4k12S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = 'openai-apikey'"
      ],
      "metadata": {
        "id": "iRjYWnMXkaLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo pip install -e EntityRelationExtraction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JheNwdwVXTuW",
        "outputId": "e26eee9f-60db-48b2-d3b2-1f27b41c0398"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/EntityRelationExtraction\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Installing collected packages: EntityRelationExtraction\n",
            "  Running setup.py develop for EntityRelationExtraction\n",
            "Successfully installed EntityRelationExtraction\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from EntityRelationExtraction.driver import Driver\n",
        "d = Driver(api_key)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVkQjl_UtLPC",
        "outputId": "b78bc5a0-a106-4050-ec84-bf3918d98055"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/configuration_utils.py:337: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
            "  \"Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = 10\n",
        "d.prepareDataSet(abstracts[:n])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNXJNu9At7IB",
        "outputId": "0bcabf43-dc5c-4904-a25e-7f943d50e774"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****************************************************************************************************\n",
            "----------------------------------------EXTRACTING ENTITIES-----------------------------------------\n",
            "****************************************************************************************************\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:01<00:00,  6.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of abstracts processed: 10\n",
            "Number of entity pairs generated: 58\n",
            "\n",
            "****************************************************************************************************\n",
            "------------------------------------FINISHED EXTRACTING ENTITIES------------------------------------\n",
            "****************************************************************************************************\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "****************************************************************************************************\n",
            "---------------------------------EXTRACTING ENTITIES RELATIONSHIPS----------------------------------\n",
            "****************************************************************************************************\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [01:13<00:00,  7.34s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of rows processed: 58\n",
            "Number of rows direct verb approach processed: 21\n",
            "Number of rows paraphraser approach processed: 8\n",
            "Number of rows GPT 3 approach processed: 23\n",
            "Rows Dropped: 6\n",
            "\n",
            "****************************************************************************************************\n",
            "-----------------------------FINISHED EXTRACTING ENTITIES RELATIONSHIPS-----------------------------\n",
            "****************************************************************************************************\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "****************************************************************************************************\n",
            "--------------------------------------CLUSTERING RELATIONSHIPS--------------------------------------\n",
            "****************************************************************************************************\n",
            "\n",
            "Total input length: 52\n",
            "....................................................................................................\n",
            "Checking words not in model vocabulary: \n",
            "\n",
            "'summarise                       '       \n",
            "\n",
            "Total number of words not in dictionary is 1.\n",
            "....................................................................................................\n",
            "Valid row count: 51\n",
            "....................................................................................................\n",
            "Start clustering\n",
            "Finished clustering\n",
            "Cluster centers count: 23    with threshold of 0.7\n",
            "....................................................................................................\n",
            "Start inferencing cluster center word\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 23/23 [00:16<00:00,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Finished inferencing cluster center word\n",
            "\n",
            "****************************************************************************************************\n",
            "---------------------------------FINISHED CLUSTERING RELATIONSHIPS----------------------------------\n",
            "****************************************************************************************************\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Done! Result dataset can be found in result/result.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "aOm1Qd9beARk"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0f3633cf17e244cf9c17e18f074ffd85": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2f5552fea4da4d858d1fba2c8a01ab81": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "392539877f58454985e093b71c44809a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46f8c38bf4be44fb96a72b5e3d343a34": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d1672e3c4d9f48f1af411aabb33228df",
              "IPY_MODEL_8782b8f894444c9aaa095f865f306ba2",
              "IPY_MODEL_d2f02a1ab9904c379741a4878dfc538d"
            ],
            "layout": "IPY_MODEL_392539877f58454985e093b71c44809a"
          }
        },
        "6caf30d1f43345ac8601fc3ad5cf668f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "750a172e34a34850ad655cdc9ba3e53a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86789169614248eeab098764b774780b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8782b8f894444c9aaa095f865f306ba2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a43f7a9a3d814e54912c78a4ee786a51",
            "max": 2950841345,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0f3633cf17e244cf9c17e18f074ffd85",
            "value": 2950841345
          }
        },
        "a43f7a9a3d814e54912c78a4ee786a51": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1672e3c4d9f48f1af411aabb33228df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_750a172e34a34850ad655cdc9ba3e53a",
            "placeholder": "​",
            "style": "IPY_MODEL_86789169614248eeab098764b774780b",
            "value": "Downloading: 100%"
          }
        },
        "d2f02a1ab9904c379741a4878dfc538d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f5552fea4da4d858d1fba2c8a01ab81",
            "placeholder": "​",
            "style": "IPY_MODEL_6caf30d1f43345ac8601fc3ad5cf668f",
            "value": " 2.75G/2.75G [00:58&lt;00:00, 50.5MB/s]"
          }
        },
        "6ada5b427290462ca0abb4461107537a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_270f0c1a29c6470ba771c74c41048506",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1d97f8ef12e84f2084d75bc01a9a57d7",
              "IPY_MODEL_a21bd192e8514638b25fece1dee265e2",
              "IPY_MODEL_0a51a5cd5e7248a78e1ce8e3f90f05f4"
            ]
          }
        },
        "270f0c1a29c6470ba771c74c41048506": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1d97f8ef12e84f2084d75bc01a9a57d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_98adf8b9ca474bbcb03aa9aeebc9a5ce",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_32a5551dd82940f1aa6caed53b8b90ab"
          }
        },
        "a21bd192e8514638b25fece1dee265e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1af0080d371e4010a6c8701631dd68bd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 200,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 200,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8a269c8133b240a7bb0a971a30f6653d"
          }
        },
        "0a51a5cd5e7248a78e1ce8e3f90f05f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d75c5afcd79345c3a5053676c798095a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 200/200 [34:21&lt;00:00, 12.37s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_27a66e66ab564e4988269a9334f615dd"
          }
        },
        "98adf8b9ca474bbcb03aa9aeebc9a5ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "32a5551dd82940f1aa6caed53b8b90ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1af0080d371e4010a6c8701631dd68bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8a269c8133b240a7bb0a971a30f6653d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d75c5afcd79345c3a5053676c798095a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "27a66e66ab564e4988269a9334f615dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}