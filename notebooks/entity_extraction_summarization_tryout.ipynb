{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "aOm1Qd9beARk"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# VM Environment Setup (No Need to Run Every Time)"
      ],
      "metadata": {
        "id": "aOm1Qd9beARk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "**install spacy**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JjICiFSxJDkZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tc3SzYyCEU5I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a79f6bc-29cf-4a06-f73d-cb82f8d5a0b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (22.2.2)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/base_command.py\", line 167, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/req_command.py\", line 247, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/commands/install.py\", line 370, in run\n",
            "    reqs, check_supported_wheels=not options.target_dir\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 93, in resolve\n",
            "    collected.requirements, max_rounds=try_to_avoid_resolution_too_deep\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 481, in resolve\n",
            "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 348, in resolve\n",
            "    self._add_to_criteria(self.state.criteria, r, parent=None)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 172, in _add_to_criteria\n",
            "    if not criterion.candidates:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/resolvelib/structs.py\", line 151, in __bool__\n",
            "    return bool(self._sequence)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 155, in __bool__\n",
            "    return any(self)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 143, in <genexpr>\n",
            "    return (c for c in iterator if id(c) not in self._incompatible_ids)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 90, in _iter_built_with_inserted\n",
            "    for version, func in infos:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 282, in iter_index_candidate_infos\n",
            "    hashes=hashes,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/index/package_finder.py\", line 889, in find_best_candidate\n",
            "    candidates = self.find_all_candidates(project_name)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/index/package_finder.py\", line 830, in find_all_candidates\n",
            "    page_candidates = list(page_candidates_it)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/index/sources.py\", line 134, in page_candidates\n",
            "    yield from self._candidates_from_page(self._link)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/index/package_finder.py\", line 799, in process_project_url\n",
            "    links=page_links,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/index/package_finder.py\", line 777, in evaluate_links\n",
            "    candidate = self.get_install_candidate(link_evaluator, link)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/index/package_finder.py\", line 758, in get_install_candidate\n",
            "    result, detail = link_evaluator.evaluate_link(link)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/index/package_finder.py\", line 247, in evaluate_link\n",
            "    logger.debug(\"Found link %s, version: %s\", link, version)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1366, in debug\n",
            "    self._log(DEBUG, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1514, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1524, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1586, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 896, in handle\n",
            "    self.release()\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 845, in release\n",
            "    def release(self):\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/main.py\", line 70, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
            "    return self._main(args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/base_command.py\", line 221, in _main\n",
            "    return run(options, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/base_command.py\", line 204, in exc_logging_wrapper\n",
            "    logger.critical(\"Operation cancelled by user\")\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1425, in critical\n",
            "    self._log(CRITICAL, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1513, in _log\n",
            "    exc_info, func, extra, sinfo)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1483, in makeRecord\n",
            "    sinfo)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 317, in __init__\n",
            "    self.module = os.path.splitext(self.filename)[0]\n",
            "  File \"/usr/lib/python3.7/posixpath.py\", line 122, in splitext\n",
            "    p = os.fspath(p)\n",
            "KeyboardInterrupt\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (3.4.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (21.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.6)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.10.0.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.6)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.4.4)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.21.5)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (8.1.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.3.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.62.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (65.4.1)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.6.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.7.0)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mException ignored in: <function _get_module_lock.<locals>.cb at 0x7f30d2479680>\n",
            "Traceback (most recent call last):\n",
            "  File \"<frozen importlib._bootstrap>\", line 177, in cb\n",
            "KeyboardInterrupt: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 183, in _run_module_as_main\n",
            "    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 142, in _get_module_details\n",
            "    return _get_module_details(pkg_main_name, error)\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 109, in _get_module_details\n",
            "    __import__(pkg_name)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/spacy/__init__.py\", line 6, in <module>\n",
            "    from .errors import setup_default_warnings\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/spacy/errors.py\", line 2, in <module>\n",
            "    from .compat import Literal\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/spacy/compat.py\", line 3, in <module>\n",
            "    from thinc.util import copy_array\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/thinc/__init__.py\", line 5, in <module>\n",
            "    from .config import registry\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/thinc/config.py\", line 4, in <module>\n",
            "    from .types import Decorator\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/thinc/types.py\", line 7, in <module>\n",
            "    from .compat import has_cupy, cupy\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/thinc/compat.py\", line 56, in <module>\n",
            "    import tensorflow.experimental.dlpack\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/__init__.py\", line 37, in <module>\n",
            "    from tensorflow.python.tools import module_util as _module_util\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/__init__.py\", line 45, in <module>\n",
            "    from tensorflow.python.feature_column import feature_column_lib as feature_column\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/feature_column/feature_column_lib.py\", line 18, in <module>\n",
            "    from tensorflow.python.feature_column.feature_column import *\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/feature_column/feature_column.py\", line 143, in <module>\n",
            "    from tensorflow.python.layers import base\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/layers/base.py\", line 16, in <module>\n",
            "    from tensorflow.python.keras.legacy_tf_layers import base\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/__init__.py\", line 22, in <module>\n",
            "    from tensorflow.python.keras import distribute\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/distribute/__init__.py\", line 18, in <module>\n",
            "    from tensorflow.python.keras.distribute import sidecar_evaluator\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/distribute/sidecar_evaluator.py\", line 24, in <module>\n",
            "    from tensorflow.python.training.tracking import util as tracking_util\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/util.py\", line 54, in <module>\n",
            "    from tensorflow.python.training.tracking import graph_view as graph_view_lib\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/graph_view.py\", line 25, in <module>\n",
            "    from tensorflow.python.training import optimizer as optimizer_v1\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/optimizer.py\", line 34, in <module>\n",
            "    from tensorflow.python.ops import gradients\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gradients.py\", line 20, in <module>\n",
            "    from tensorflow.python.eager.forwardprop import ForwardAccumulator\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/forwardprop.py\", line 31, in <module>\n",
            "    from tensorflow.python.ops.parallel_for import control_flow_ops\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/parallel_for/__init__.py\", line 20, in <module>\n",
            "    from tensorflow.python.ops.parallel_for.gradients import batch_jacobian\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/parallel_for/gradients.py\", line 19, in <module>\n",
            "    from tensorflow.python.ops import gradients_impl as gradient_ops\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gradients_impl.py\", line 22, in <module>\n",
            "    from tensorflow.python.ops import control_flow_grad  # pylint: disable=unused-import\n",
            "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 724, in exec_module\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 818, in get_code\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 916, in get_data\n",
            "KeyboardInterrupt\n",
            "Requirement already satisfied: scispacy in /usr/local/lib/python3.7/dist-packages (0.5.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from scispacy) (1.21.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from scispacy) (1.1.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scispacy) (2.23.0)\n",
            "Requirement already satisfied: nmslib>=1.7.3.6 in /usr/local/lib/python3.7/dist-packages (from scispacy) (2.1.1)\n",
            "Requirement already satisfied: pysbd in /usr/local/lib/python3.7/dist-packages (from scispacy) (0.3.4)\n",
            "Requirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from scispacy) (3.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.3 in /usr/local/lib/python3.7/dist-packages (from scispacy) (0.22.1)\n",
            "Requirement already satisfied: conllu in /usr/local/lib/python3.7/dist-packages (from scispacy) (4.5.2)\n",
            "Requirement already satisfied: pybind11<2.6.2 in /usr/local/lib/python3.7/dist-packages (from nmslib>=1.7.3.6->scispacy) (2.6.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from nmslib>=1.7.3.6->scispacy) (5.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->scispacy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->scispacy) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->scispacy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->scispacy) (2.10)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.3->scispacy) (1.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->scispacy) (3.0.6)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->scispacy) (0.3.2)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->scispacy) (0.6.2)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->scispacy) (1.0.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->scispacy) (2.0.6)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->scispacy) (3.10.0.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->scispacy) (1.8.2)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->scispacy) (8.1.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->scispacy) (21.3)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->scispacy) (3.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->scispacy) (2.11.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->scispacy) (0.10.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->scispacy) (4.62.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->scispacy) (65.4.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->scispacy) (2.0.8)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->scispacy) (3.0.10)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->scispacy) (2.4.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->scispacy) (1.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.5.0,>=3.4.0->scispacy) (3.7.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->scispacy) (3.0.7)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->scispacy) (5.2.1)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->scispacy) (0.0.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->scispacy) (0.7.8)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->scispacy) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->scispacy) (2.0.1)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mProcessing ./scispacy_model/en_core_sci_scibert-0.5.1.tar.gz\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/base_command.py\", line 167, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/req_command.py\", line 247, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/commands/install.py\", line 370, in run\n",
            "    reqs, check_supported_wheels=not options.target_dir\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 73, in resolve\n",
            "    collected = self.factory.collect_root_requirements(root_reqs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 493, in collect_root_requirements\n",
            "    requested_extras=(),\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 458, in _make_requirement_from_install_req\n",
            "    version=None,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 211, in _make_candidate_from_link\n",
            "    version=version,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 303, in __init__\n",
            "    version=version,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 162, in __init__\n",
            "    self.dist = self._prepare()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 231, in _prepare\n",
            "    dist = self._prepare_distribution()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 308, in _prepare_distribution\n",
            "    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/operations/prepare.py\", line 438, in prepare_linked_requirement\n",
            "    return self._prepare_linked_requirement(req, parallel_builds)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/operations/prepare.py\", line 489, in _prepare_linked_requirement\n",
            "    hashes,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/operations/prepare.py\", line 175, in unpack_url\n",
            "    unpack_file(file.path, location, file.content_type)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/utils/unpacking.py\", line 246, in unpack_file\n",
            "    untar_file(filename, location)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/utils/unpacking.py\", line 175, in untar_file\n",
            "    leading = has_leading_dir([member.name for member in tar.getmembers()])\n",
            "  File \"/usr/lib/python3.7/tarfile.py\", line 1763, in getmembers\n",
            "    self._load()        # all members, we first have to\n",
            "  File \"/usr/lib/python3.7/tarfile.py\", line 2350, in _load\n",
            "    tarinfo = self.next()\n",
            "  File \"/usr/lib/python3.7/tarfile.py\", line 2281, in next\n",
            "    self.fileobj.seek(self.offset - 1)\n",
            "  File \"/usr/lib/python3.7/gzip.py\", line 379, in seek\n",
            "    return self._buffer.seek(offset, whence)\n",
            "  File \"/usr/lib/python3.7/_compression.py\", line 143, in seek\n",
            "    data = self.read(min(io.DEFAULT_BUFFER_SIZE, offset))\n",
            "  File \"/usr/lib/python3.7/gzip.py\", line 482, in read\n",
            "    uncompress = self._decompressor.decompress(buf, size)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/main.py\", line 70, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
            "    return self._main(args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/base_command.py\", line 221, in _main\n",
            "    return run(options, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/base_command.py\", line 204, in exc_logging_wrapper\n",
            "    logger.critical(\"Operation cancelled by user\")\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1425, in critical\n",
            "    self._log(CRITICAL, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1514, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1524, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1586, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 894, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/utils/logging.py\", line 177, in emit\n",
            "    self.console.print(renderable, overflow=\"ignore\", crop=False, style=style)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/rich/console.py\", line 1678, in print\n",
            "    render(renderable, render_options), self.get_style(style)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/rich/segment.py\", line 199, in <genexpr>\n",
            "    cls(text, None if control else apply(_style), control)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/rich/console.py\", line 1305, in render\n",
            "    for render_output in iter_render:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/rich/text.py\", line 639, in __rich_console__\n",
            "    no_wrap=pick_bool(self.no_wrap, options.no_wrap, False),\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/rich/text.py\", line 1156, in wrap\n",
            "    for line in self.split(allow_blank=True):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/rich/text.py\", line 1003, in split\n",
            "    assert separator, \"separator must not be empty\"\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "# \n",
        "!pip install -U pip setuptools wheel\n",
        "!pip install -U spacy\n",
        "!python -m spacy download en_core_web_trf\n",
        "!pip install scispacy\n",
        "!pip install \"scispacy_model/en_core_sci_scibert-0.5.1.tar.gz\"\n",
        "#!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.4.0/en_ner_bc5cdr_md-0.4.0.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy validate"
      ],
      "metadata": {
        "id": "yLqAo_tyDrRY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c69f610-8742-45e0-d4d1-1826f035bceb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-10-03 00:29:11.312643: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "\u001b[2K\u001b[38;5;2m✔ Loaded compatibility table\u001b[0m\n",
            "\u001b[1m\n",
            "================= Installed pipeline packages (spaCy v3.4.1) =================\u001b[0m\n",
            "\u001b[38;5;4mℹ spaCy installation: /usr/local/lib/python3.7/dist-packages/spacy\u001b[0m\n",
            "\n",
            "NAME                  SPACY            VERSION                            \n",
            "en_ner_bc5cdr_md      >=3.0.1,<3.1.0   \u001b[38;5;3m0.4.0\u001b[0m   --> n/a       \n",
            "en_core_sci_sm        >=3.4.1,<3.5.0   \u001b[38;5;2m0.5.1\u001b[0m   \u001b[38;5;2m✔\u001b[0m\n",
            "en_core_sci_scibert   >=3.4.1,<3.5.0   \u001b[38;5;2m0.5.1\u001b[0m   \u001b[38;5;2m✔\u001b[0m\n",
            "en_core_web_trf       >=3.4.0,<3.5.0   \u001b[38;5;2m3.4.0\u001b[0m   \u001b[38;5;2m✔\u001b[0m\n",
            "\n",
            "\u001b[38;5;4mℹ The following packages are custom spaCy pipelines or not available\n",
            "for spaCy v3.4.1:\u001b[0m\n",
            "en_ner_bc5cdr_md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.8.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "piWRGqWAdNNT",
        "outputId": "db1960ba-8676-40b0-b54c-aa0f2db8123d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch==1.8.0 in /usr/local/lib/python3.7/dist-packages (1.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0) (1.21.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0) (3.10.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**install OpenNRE**"
      ],
      "metadata": {
        "id": "5gmK7By5JSkl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/thunlp/OpenNRE.git"
      ],
      "metadata": {
        "id": "U7XyQ9hiGkH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd OpenNRE"
      ],
      "metadata": {
        "id": "hmQJRCL5Iiyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "6qh7Pu-0IqVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python setup.py install"
      ],
      "metadata": {
        "id": "LhOL0adkIqd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ../"
      ],
      "metadata": {
        "id": "UkGhT655dktZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**install sentencepiece for transformers dependencies**"
      ],
      "metadata": {
        "id": "oSZesWH5ewNy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==4.11.0 # last version 4.1.0\n",
        "!pip install sentencepiece"
      ],
      "metadata": {
        "id": "qLepxKvKfCZ-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 786
        },
        "outputId": "08a17f1a-3291-4f27-867d-a031afdb9ea3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.11.0\n",
            "  Downloading transformers-4.11.0-py3-none-any.whl (2.9 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.4/2.9 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m2.2/2.9 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.11.0) (1.21.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.11.0) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.11.0) (4.62.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.11.0) (3.6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.11.0) (2022.9.13)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.11.0) (0.0.53)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.11.0) (21.3)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.11.0) (4.11.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.0.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.11.0) (0.10.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.11.0) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.17->transformers==4.11.0) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.11.0) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.11.0) (3.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.11.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.11.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.11.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.11.0) (2021.10.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.11.0) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.11.0) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.11.0) (7.1.2)\n",
            "Installing collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.9.4\n",
            "    Uninstalling tokenizers-0.9.4:\n",
            "      Successfully uninstalled tokenizers-0.9.4\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.1.0\n",
            "    Uninstalling transformers-4.1.0:\n",
            "      Successfully uninstalled transformers-4.1.0\n",
            "Successfully installed tokenizers-0.10.3 transformers-4.11.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tokenizers",
                  "transformers"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.97)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**install pubmed-parser**"
      ],
      "metadata": {
        "id": "Z_pMYlv6cadb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pubmed-parser"
      ],
      "metadata": {
        "id": "E6-Fg3CHNy-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**install gensim**"
      ],
      "metadata": {
        "id": "YDrUSe47yXeH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKZAT_TAyW4v",
        "outputId": "ff35e6b6-23ad-4a6d-dcf6-9206497ebda9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Collecting gensim\n",
            "  Downloading gensim-4.2.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.1 MB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.7.3)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n",
            "Installing collected packages: gensim\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed gensim-4.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dTGeW6FHQkyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main Scripts"
      ],
      "metadata": {
        "id": "bCfQEdKbd4Ze"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Connect to MongoDB and Load PubMed Data**"
      ],
      "metadata": {
        "id": "XTEhxFbrMJ0c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pymongo\n",
        "client = pymongo.MongoClient(\"mongodb://cosmosdbcolumbiacapstonefall2022:alv0mZxNDjmu37OvR0USNaFrT694JwXE8qpdmb62KSRhHZbZIHaiIw7KqceRlSwFRmhhqFCfdtCKDEnWXh9w8Q==@cosmosdbcolumbiacapstonefall2022.mongo.cosmos.azure.com:10255/?ssl=true&replicaSet=globaldb&retrywrites=false&maxIdleTimeMS=120000&appName=@cosmosdbcolumbiacapstonefall2022@\")\n",
        "# Database Name\n",
        "db = client['pubmed']\n",
        "# Collection Name\n",
        "col = db['abstracts']\n",
        "\n",
        "abstracts = col.find({},{'_id':0, 'text':1})\n",
        "abstracts = [a['text'] for a in abstracts]"
      ],
      "metadata": {
        "id": "6rUtQypYMIPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(abstracts[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee4dtfu1TD_w",
        "outputId": "8df09e80-08a3-4681-e475-ad844adabefd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Severe COVID-19 is associated with venous thromboembolic events and and immuno-thrombotic phenomena, responsible for pulmonary vascular damage. This review summarizes the current knowledge on thrombotic risk in COVID-19 inpatients, the potential predictive factors (including D-dimer) and the randomized trials studying the effect of intermediate or therapeutic-dose anticoagulation on the clinical and thrombotic prognosis. Despite the initial hope, therapeutic anticoagulation does not improve the clinical prognosis in critically ill inpatients, and standard prophylactic anticoagulation is therefore recommended. In non-critical inpatients, the use of therapeutic anticoagulation may help reduce the risk of severe clinical deterioration, but its risk-benefit will be clarified in ongoing studies and meta-analyzes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Use NER to extract entities**"
      ],
      "metadata": {
        "id": "VhLSadL0Mo2C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import spacy\n",
        "%cd /content\n",
        "with open(\"/content/simple_dict.txt\",\"rb\") as file:\n",
        "  simple_dict = pickle.load(file)\n",
        "nlp = spacy.load(\"en_core_sci_scibert\")\n",
        "\n",
        "def entity_extraction(text_input):\n",
        "  doc = nlp(text_input)\n",
        "  text_entity_list = []\n",
        "  for sentence in doc.sents:\n",
        "    sentence_entity_list = []\n",
        "    entity_start = -1\n",
        "    entity_end = -1\n",
        "    and_keyword_connecting = False\n",
        "    prev_adp = False\n",
        "\n",
        "    for token in sentence:\n",
        "      if (token.ent_type != 0 and token.tag_ == 'JJ'):\n",
        "        if entity_start == -1: # Entering a new entity\n",
        "          entity_start = token.idx\n",
        "      elif (token.ent_type != 0 and token.pos_ == 'NOUN'):\n",
        "        if entity_start == -1: # Entering a new entity\n",
        "          entity_start = token.idx\n",
        "        entity_end = token.idx + len(token) # Possible to end an entity here\n",
        "      elif token.ent_type != 0 and not prev_adp:\n",
        "        entity_start = -1\n",
        "        entity_end = -1\n",
        "        prev_adp = False\n",
        "      elif (token.text == \"of\"): #ignore the previous entity\n",
        "        entity_start = -1\n",
        "        entity_end = -1\n",
        "      elif (token.pos_ == 'ADP'):\n",
        "        prev_adp = True\n",
        "      elif (token.text == \"and\" and entity_end == -1): #if not yet reaches the end of an entity\n",
        "        continue\n",
        "      else: \n",
        "        #checks if an entity has been formed\n",
        "        if (entity_start != -1 and entity_end != -1):\n",
        "          if and_keyword_connecting and (entity_end - sentence_entity_list[-1]['end'] <= 30): \n",
        "            #if close enough with previous entity and connected by \"AND\"\n",
        "            sentence_entity_list[-1]['end'] = entity_end\n",
        "          else: \n",
        "            #if is an independent entity\n",
        "            sentence_entity_list.append({\"start\": entity_start, \"end\": entity_end, \"label\": \"Entity\"})\n",
        "          and_keyword_connecting = False\n",
        "\n",
        "        elif token.pos_ == \"NOUN\" and and_keyword_connecting:\n",
        "          #if is a noun (but not recognized as an entity) and should be connected by AND keyword\n",
        "          if (token.idx + len(token) - sentence_entity_list[-1]['end'] <= 30):\n",
        "            sentence_entity_list[-1]['end'] = token.idx + len(token)\n",
        "          and_keyword_connecting = False\n",
        "        \n",
        "        if token.text == 'and':\n",
        "          and_keyword_connecting = True\n",
        "\n",
        "        entity_start = -1\n",
        "        entity_end = -1\n",
        "\n",
        "\n",
        "    for ent in sentence_entity_list:\n",
        "      start_index = ent['start']\n",
        "      end_index = ent['end']\n",
        "      entity_text = doc.text[start_index:end_index].lower()\n",
        "\n",
        "      #Only consider it to be an entity if it is not a simple word\n",
        "      if entity_text not in simple_dict:\n",
        "        text_entity_list.append(ent)\n",
        "\n",
        "\n",
        "\n",
        "  ex = {\n",
        "      \"text\": doc.text,\n",
        "      \"ents\": text_entity_list,\n",
        "      \"title\": None\n",
        "  }\n",
        "\n",
        "  spacy.displacy.render(ex , style='ent', manual=True, jupyter=True)\n",
        "\n",
        "  return ex"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JeGZVhuvExKK",
        "outputId": "caedfaf4-67aa-4c88-d3e0-efbafa6aff55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/configuration_utils.py:337: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
            "  \"Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = abstracts[10]\n",
        "ex = entity_extraction(input_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "r-qYdodXFEnI",
        "outputId": "6129fd6f-4e3c-4558-cb77-130e88bee508"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/cuda/amp/autocast_mode.py:117: UserWarning: torch.cuda.amp.autocast only affects CUDA ops, but CUDA is not available.  Disabling.\n",
            "  warnings.warn(\"torch.cuda.amp.autocast only affects CUDA ops, but CUDA is not available.  Disabling.\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Extracellular matrixes\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Entity</span>\n",
              "</mark>\n",
              " (\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    ECMs\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Entity</span>\n",
              "</mark>\n",
              "), such as the \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    cell walls and biofilms\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Entity</span>\n",
              "</mark>\n",
              ", are important for supporting \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    cell integrity and function\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Entity</span>\n",
              "</mark>\n",
              " and regulating \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    intercellular communication\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Entity</span>\n",
              "</mark>\n",
              ". These \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    biomaterials\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Entity</span>\n",
              "</mark>\n",
              " are also of significant interest to the production of \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    biofuels\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Entity</span>\n",
              "</mark>\n",
              " and the development of \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    antimicrobial treatment\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Entity</span>\n",
              "</mark>\n",
              ". \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Solid-state nuclear magnetic resonance\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Entity</span>\n",
              "</mark>\n",
              " (\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    ssNMR\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Entity</span>\n",
              "</mark>\n",
              ") and \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    magic-angle spinning-dynamic nuclear polarization\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Entity</span>\n",
              "</mark>\n",
              " (\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    MAS-DNP\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Entity</span>\n",
              "</mark>\n",
              ") are uniquely powerful for understanding the \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    conformational structure\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Entity</span>\n",
              "</mark>\n",
              ", \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    dynamical characteristics\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Entity</span>\n",
              "</mark>\n",
              ", and supramolecular assemblies of \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    carbohydrates and other biomolecules\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Entity</span>\n",
              "</mark>\n",
              " in \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    ECMs\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Entity</span>\n",
              "</mark>\n",
              ". This review highlights the recent high-resolution investigations of \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    intact ECMs and native cells\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Entity</span>\n",
              "</mark>\n",
              " in many \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    organisms\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Entity</span>\n",
              "</mark>\n",
              " spanning across \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    plants\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Entity</span>\n",
              "</mark>\n",
              ", bacteria, \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    fungi\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Entity</span>\n",
              "</mark>\n",
              ", and \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    algae\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Entity</span>\n",
              "</mark>\n",
              ". We spotlight the \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    structural principles\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Entity</span>\n",
              "</mark>\n",
              " identified in \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    ECMs\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Entity</span>\n",
              "</mark>\n",
              ", discuss the current \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    technical limitation\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Entity</span>\n",
              "</mark>\n",
              " and underexplored biochemical topics, and point out the promising \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    opportunities\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Entity</span>\n",
              "</mark>\n",
              " enabled by the recent advances of the rapidly evolving \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    ssNMR technology\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Entity</span>\n",
              "</mark>\n",
              ".</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**auto-summarization transformers**"
      ],
      "metadata": {
        "id": "moGXBmfhVWuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN XSUM"
      ],
      "metadata": {
        "id": "u-S1IfN2mPHc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "\n",
        "# Download configuration from huggingface.co (user-uploaded) and cached, use cache_dir to change cache dir\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"sysresearch101/t5-large-finetuned-xsum-cnn\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"sysresearch101/t5-large-finetuned-xsum-cnn\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jZz-YxLQc-B",
        "outputId": "b41279a6-bf05-487e-eff1-a296661a223e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/configuration_utils.py:337: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
            "  \"Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# abstract[10][0]\n",
        "import torch \n",
        "ARTICLE_TO_SUMMARIZE = '''Extracellular matrixes (ECMs), such as the cell walls and biofilms,\n",
        "are important for supporting cell integrity and function and regulating intercellular communication.'''\n",
        "ARTICLE_TO_SUMMARIZE_MASKED = '''[MASK], such as the [MASK], \n",
        "are important for supporting [MASK] and regulating [MASK].'''\n",
        "\n",
        "# code to mask entity\n",
        "'''\n",
        "entity = [\"Extracellular\", 'matrixes', '(ECMs)', 'cell']\n",
        "split_words = ARTICLE_TO_SUMMARIZE.split(' ')\n",
        "masked_index = []\n",
        "for i, word in enumerate(split_words):\n",
        "  if word in entity:\n",
        "    masked_index.append(i) \n",
        "\n",
        "match_idxs = torch.LongTensor([[wid not in masked_index for wid in encoded.word_ids(0)]])\n",
        "print(\"Subword indices of matching word\", match_idxs)\n",
        "\n",
        "# Merge: if a word is zero in our custom match, merge, if not, use the original mask\n",
        "# This ensures that we mask the word IDs but keep the original mask for special tokens (cls, pad, etc.)\n",
        "merged = torch.where(match_idxs == 0, match_idxs, encoded[\"attention_mask\"])\n",
        "print(\"Merged mask\", merged)\n",
        "'''"
      ],
      "metadata": {
        "id": "XVmLLAT4VDIb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "19a6a945-226e-4905-f26a-a20b3df4adb9"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nentity = [\"Extracellular\", \\'matrixes\\', \\'(ECMs)\\', \\'cell\\']\\nsplit_words = ARTICLE_TO_SUMMARIZE.split(\\' \\')\\nmasked_index = []\\nfor i, word in enumerate(split_words):\\n  if word in entity:\\n    masked_index.append(i) \\n\\nmatch_idxs = torch.LongTensor([[wid not in masked_index for wid in encoded.word_ids(0)]])\\nprint(\"Subword indices of matching word\", match_idxs)\\n\\n# Merge: if a word is zero in our custom match, merge, if not, use the original mask\\n# This ensures that we mask the word IDs but keep the original mask for special tokens (cls, pad, etc.)\\nmerged = torch.where(match_idxs == 0, match_idxs, encoded[\"attention_mask\"])\\nprint(\"Merged mask\", merged)\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tokenizer(ARTICLE_TO_SUMMARIZE_MASKED, return_tensors='pt')\n",
        "input_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDFlRMJvYkZK",
        "outputId": "df8c4a02-0f0d-4fa3-b16c-d9481013269a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[  784, 23010,   439, 13679,   224,    38,     8,   784, 23010,   439,\n",
              "         13679,    33,   359,    21,  3956,   784, 23010,   439,   908,    11,\n",
              "             3, 27321,   784, 23010,   439,  4275,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1]])}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "problem:\n",
        "1. 1 to many relationship. i.e. ECMs support cell integrity and function; ECMs regulate intercellular communication. How to identify this and use ECMs twice\n",
        "2. mask ner and decode"
      ],
      "metadata": {
        "id": "LERP3joEYIe1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tokenizer.encode(ARTICLE_TO_SUMMARIZE_MASKED, return_tensors='pt')\n",
        "summary_ids = model.generate(input_ids,\n",
        "            min_length=20,\n",
        "            max_length=80,\n",
        "            num_beams=10,\n",
        "            repetition_penalty=2.5,\n",
        "            length_penalty=1.0,\n",
        "            early_stopping=True,\n",
        "            no_repeat_ngram_size=2,\n",
        "            use_cache=True,\n",
        "            do_sample = True,\n",
        "            temperature = 0.8,\n",
        "            top_k = 50,\n",
        "            top_p = 0.95)\n",
        "\n",
        "summary_text = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "print(summary_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqE1GijKQuSa",
        "outputId": "322ce5cd-4b9d-437f-9198-fc223d94fe33"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[MASK] is a global network of people, organisations and institutions that work together to improve the lives of children.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "after_ner = '''A are important for supporting B'''"
      ],
      "metadata": {
        "id": "2qOunFgSY3fJ"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tokenizer.encode(after_ner, return_tensors='pt')\n",
        "summary_ids = model.generate(input_ids,\n",
        "            min_length = 1,\n",
        "            max_length=80,\n",
        "            num_beams=10,\n",
        "            repetition_penalty=2.5,\n",
        "            length_penalty=5.0,\n",
        "            early_stopping=True,\n",
        "            no_repeat_ngram_size=2,\n",
        "            use_cache=True,\n",
        "            do_sample = True,\n",
        "            temperature = 0.8,\n",
        "            top_k = 50,\n",
        "            top_p = 0.95)\n",
        "\n",
        "summary_text = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "print(summary_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTz-up68ZDyj",
        "outputId": "153429cf-2d7f-469d-dd0e-c0f1224aa71a"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A and B are important for supporting the development of C.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(input_ids[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_f6tGSdaTJ9",
        "outputId": "2ba87caf-228b-46b0-d5e9-14ba3a598455"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model not working. Add in non-related info"
      ],
      "metadata": {
        "id": "av6lDcvOn7sG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# explore other models\n",
        "import re\n",
        "from transformers import AutoTokenizer, T5ForConditionalGeneration\n",
        "\n",
        "WHITESPACE_HANDLER = lambda k: re.sub('\\s+', ' ', re.sub('\\n+', ' ', k.strip()))\n",
        "\n",
        "model_name = \"JulesBelveze/t5-small-headline-generator\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElrPJjMZiRQx",
        "outputId": "c82e033e-5063-4018-f3f1-4371032d9599"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/configuration_utils.py:337: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
            "  \"Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "input_ids = tokenizer(\n",
        "    [WHITESPACE_HANDLER(ARTICLE_TO_SUMMARIZE)],\n",
        "    return_tensors=\"pt\",\n",
        "    padding=\"max_length\",\n",
        "    truncation=True,\n",
        "    max_length=20\n",
        ")[\"input_ids\"]\n",
        "\n",
        "output_ids = model.generate(\n",
        "    input_ids=input_ids,\n",
        "    max_length=20,\n",
        "    no_repeat_ngram_size=2,\n",
        "    num_beams=4\n",
        ")[0]\n",
        "\n",
        "summary = tokenizer.decode(\n",
        "    output_ids,\n",
        "    skip_special_tokens=True,\n",
        "    clean_up_tokenization_spaces=False\n",
        ")\n",
        "print(summary)\n",
        "\n",
        "# change hyperparameter\n",
        "input_ids = tokenizer(\n",
        "    [WHITESPACE_HANDLER(ARTICLE_TO_SUMMARIZE)],\n",
        "    return_tensors=\"pt\",\n",
        "    padding=\"max_length\",\n",
        "    truncation=True,\n",
        "    max_length=80\n",
        ")[\"input_ids\"]\n",
        "\n",
        "output_ids = model.generate(input_ids,\n",
        "            min_length=20,\n",
        "            max_length=80,\n",
        "            num_beams=10,\n",
        "            repetition_penalty=2.5,\n",
        "            length_penalty=1.0,\n",
        "            early_stopping=True,\n",
        "            no_repeat_ngram_size=2,\n",
        "            use_cache=True,\n",
        "            do_sample = True,\n",
        "            temperature = 0.8,\n",
        "            top_k = 50,\n",
        "            top_p = 0.95\n",
        ")[0]\n",
        "\n",
        "summary = tokenizer.decode(\n",
        "    output_ids,\n",
        "    skip_special_tokens=True,\n",
        "    clean_up_tokenization_spaces=False\n",
        ")\n",
        "print(summary)"
      ],
      "metadata": {
        "id": "2vfT3TO4aiOh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "faaacf65-7e79-446e-ae5d-d66437d392cd"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-Matrix Extracellular Matrixes (ECMs), such\n",
            ": Extracellular matrixes (ECMs), such as cell walls and biofilms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Truncate the text. \n",
        "Most models work with long texts. i.e. summarizing an article to 1 sentence"
      ],
      "metadata": {
        "id": "Hr2gjBgUmkeV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# scifive: https://github.com/justinphan3110/SciFive\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"razent/SciFive-large-Pubmed_PMC-MedNLI\")  \n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"razent/SciFive-large-Pubmed_PMC-MedNLI\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fJ95i42N0Y5",
        "outputId": "9306abbe-f623-403e-82d5-1aaeeb62106b"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/configuration_utils.py:337: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
            "  \"Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent_1 = \"Extracellular matrixes (ECMs) are important for supporting cell integrity and function and regulating intercellular communication\"\n",
        "sent_2 = \"cell integrity and function and regulating intercellular communication\"\n",
        "text =  f\"mednli: sentence1: {sent_1} sentence2: {sent_2}\"\n",
        "\n",
        "encoding = tokenizer.encode_plus(sent_1, padding='max_length', max_length=50, return_tensors=\"pt\")\n",
        "input_ids, attention_masks = encoding[\"input_ids\"], encoding[\"attention_mask\"]\n",
        "outputs = model.generate(\n",
        "    input_ids=input_ids, attention_mask=attention_masks,\n",
        "    max_length=30,\n",
        "    length_penalty = 10,\n",
        "    early_stopping=False\n",
        ")\n",
        "\n",
        "for output in outputs:\n",
        "    line = tokenizer.decode(output, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
        "    print(line)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdYiUf-ZlHIV",
        "outputId": "fba20847-5487-4442-cd23-c8804e34701d"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. (ICs) are a major component of the extracellular matrix (ECM) that are deposited by cells\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "NohQx1LlQrNa",
        "outputId": "6e621bd5-823b-4921-aa90-786c2ea15f59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'mednli: sentence1: In the ED, initial VS revealed T 98.9, HR 73, BP 121/90, RR 15, O2 sat 98% on RA. sentence2: The patient is hemodynamically stable'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Even Worse Model"
      ],
      "metadata": {
        "id": "xwFB01H5peBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, PegasusForConditionalGeneration, PegasusTokenizer"
      ],
      "metadata": {
        "id": "75zC17U2JLc9"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "WHITESPACE_HANDLER = lambda k: re.sub('\\s+', ' ', re.sub('\\n+', ' ', k.strip()))\n",
        "\n",
        "#article_text = abstracts[0]"
      ],
      "metadata": {
        "id": "sDNBhbWRVdcs"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"csebuetnlp/mT5_multilingual_XLSum\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "xNI2fBvxJHfw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bd85d77-41d4-4b4f-f410-d61fc4a5685a"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/configuration_utils.py:337: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
            "  \"Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tokenizer(\n",
        "    [WHITESPACE_HANDLER(ARTICLE_TO_SUMMARIZE)],\n",
        "    return_tensors=\"pt\",\n",
        "    padding=\"max_length\",\n",
        "    truncation=True,\n",
        "    max_length=10\n",
        ")[\"input_ids\"]\n",
        "\n",
        "output_ids = model.generate(\n",
        "    input_ids=input_ids,\n",
        "    max_length=10,\n",
        "    no_repeat_ngram_size=2,\n",
        "    num_beams=4\n",
        ")[0]\n",
        "\n",
        "summary = tokenizer.decode(\n",
        "    output_ids,\n",
        "    skip_special_tokens=True,\n",
        "    clean_up_tokenization_spaces=False\n",
        ")\n",
        "\n",
        "print(summary)"
      ],
      "metadata": {
        "id": "TgfnG2Gfb85l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6c36260-84c3-419d-94d1-006285b81db8"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In our series of letters from scientist\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2_name = \"google/pegasus-xsum\"\n",
        "tokenizer2 = PegasusTokenizer.from_pretrained(model2_name)\n",
        "model2 = PegasusForConditionalGeneration.from_pretrained(model2_name)"
      ],
      "metadata": {
        "id": "WaHMcHgUd3F3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe9c77f7-b393-43b0-994e-bef61a2860b9"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/configuration_utils.py:337: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
            "  \"Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch = tokenizer2(ARTICLE_TO_SUMMARIZE, truncation=True, padding=\"longest\", return_tensors=\"pt\")\n",
        "translated = model2.generate(**batch)\n",
        "tgt_text = tokenizer2.batch_decode(translated, skip_special_tokens=True)\n",
        "tgt_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvOdEoXDLMlR",
        "outputId": "3b882f1e-cbe3-4eec-d844-0ed4797ce7f1"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The aim of this study is to understand the role of extracellular matrixes in the development and maintenance of healthy human tissues.']"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4f1kMm_-yuFo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}